# LLMChat ç»´æŠ¤æŒ‡å—

## ğŸ“‹ ç›®å½•
- [æ—¥å¸¸ç»´æŠ¤ä»»åŠ¡](#æ—¥å¸¸ç»´æŠ¤ä»»åŠ¡)
- [å®šæœŸç»´æŠ¤è®¡åˆ’](#å®šæœŸç»´æŠ¤è®¡åˆ’)
- [ç›‘æ§ç³»ç»Ÿ](#ç›‘æ§ç³»ç»Ÿ)
- [æ•…éšœå¤„ç†æµç¨‹](#æ•…éšœå¤„ç†æµç¨‹)
- [ç‰ˆæœ¬ç®¡ç†](#ç‰ˆæœ¬ç®¡ç†)
- [å¤‡ä»½ç­–ç•¥](#å¤‡ä»½ç­–ç•¥)
- [æ€§èƒ½è°ƒä¼˜](#æ€§èƒ½è°ƒä¼˜)

## æ—¥å¸¸ç»´æŠ¤ä»»åŠ¡

### æ¯æ—¥æ£€æŸ¥æ¸…å•

#### ç³»ç»Ÿå¥åº·æ£€æŸ¥
```bash
#!/bin/bash
# scripts/daily-health-check.sh

echo "ğŸ¥ LLMChat æ¯æ—¥å¥åº·æ£€æŸ¥ - $(date)"

# 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ğŸ“Š æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
curl -f http://localhost:3001/health || {
  echo "âŒ ä¸»æœåŠ¡å¼‚å¸¸"
  exit 1
}

# 2. æ£€æŸ¥æ•°æ®åº“è¿æ¥
echo "ğŸ—„ï¸ æ£€æŸ¥æ•°æ®åº“è¿æ¥..."
curl -f http://localhost:3001/health/db || {
  echo "âŒ æ•°æ®åº“è¿æ¥å¼‚å¸¸"
  exit 1
}

# 3. æ£€æŸ¥Redisè¿æ¥
echo "ğŸ”´ æ£€æŸ¥Redisè¿æ¥..."
curl -f http://localhost:3001/health/redis || {
  echo "âŒ Redisè¿æ¥å¼‚å¸¸"
  exit 1
}

# 4. æ£€æŸ¥ç£ç›˜ç©ºé—´
echo "ğŸ’¾ æ£€æŸ¥ç£ç›˜ç©ºé—´..."
DISK_USAGE=$(df / | awk 'NR==2 {print $5}' | sed 's/%//')
if [ $DISK_USAGE -gt 80 ]; then
  echo "âš ï¸ ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜: ${DISK_USAGE}%"
fi

# 5. æ£€æŸ¥å†…å­˜ä½¿ç”¨
echo "ğŸ§  æ£€æŸ¥å†…å­˜ä½¿ç”¨..."
MEMORY_USAGE=$(free | awk 'NR==2{printf "%.2f", $3*100/$2}')
if (( $(echo "$MEMORY_USAGE > 80" | bc -l) )); then
  echo "âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: ${MEMORY_USAGE}%"
fi

# 6. æ£€æŸ¥æ—¥å¿—é”™è¯¯
echo "ğŸ“‹ æ£€æŸ¥é”™è¯¯æ—¥å¿—..."
ERROR_COUNT=$(grep -c "ERROR" /var/log/llmchat/app.log 2>/dev/null || echo "0")
if [ $ERROR_COUNT -gt 0 ]; then
  echo "âš ï¸ å‘ç° $ERROR_COUNT ä¸ªé”™è¯¯"
fi

echo "âœ… æ¯æ—¥å¥åº·æ£€æŸ¥å®Œæˆ"
```

#### æ—¥å¿—ç›‘æ§
```typescript
// scripts/log-monitor.js
const winston = require('winston');
const fs = require('fs');

class LogMonitor {
  constructor() {
    this.logger = winston.createLogger({
      level: 'info',
      format: winston.format.combine(
        winston.format.timestamp(),
        winston.format.json()
      ),
      transports: [
        new winston.transports.File({ filename: 'log-monitor.log' })
      ]
    });
  }

  async monitorLogFile(logFile) {
    try {
      const stats = await fs.promises.stat(logFile);
      const lastModified = stats.mtime;
      const now = new Date();
      const diffHours = (now - lastModified) / (1000 * 60 * 60);

      if (diffHours > 1) {
        this.logger.warn('æ—¥å¿—æ–‡ä»¶é•¿æ—¶é—´æœªæ›´æ–°', {
          logFile,
          lastModified,
          diffHours
        });
      }

      // æ£€æŸ¥é”™è¯¯æ—¥å¿—
      const content = await fs.promises.readFile(logFile, 'utf8');
      const errorMatches = content.match(/ERROR/g);
      const errorCount = errorMatches ? errorMatches.length : 0;

      if (errorCount > 10) {
        this.logger.error('é”™è¯¯æ—¥å¿—è¿‡å¤š', {
          logFile,
          errorCount
        });
      }

    } catch (error) {
      this.logger.error('æ—¥å¿—ç›‘æ§å¤±è´¥', { error: error.message });
    }
  }

  async startMonitoring() {
    const logFiles = [
      '/var/log/llmchat/app.log',
      '/var/log/llmchat/error.log',
      '/var/log/nginx/access.log'
    ];

    for (const logFile of logFiles) {
      await this.monitorLogFile(logFile);
    }

    this.logger.info('æ—¥å¿—ç›‘æ§æ£€æŸ¥å®Œæˆ');
  }
}

// å¯åŠ¨ç›‘æ§
const monitor = new LogMonitor();
monitor.startMonitoring();
```

### åº”ç”¨ç¨‹åºç›‘æ§

#### è‡ªå®šä¹‰å¥åº·æ£€æŸ¥ç«¯ç‚¹
```typescript
// backend/src/health/health.controller.ts
@Controller('health')
export class HealthController {
  constructor(
    private readonly databaseService: DatabaseService,
    private readonly redisService: RedisService,
    private readonly metricsService: MetricsService
  ) {}

  @Get()
  async getHealthStatus(): Promise<HealthResponse> {
    const checks = await Promise.allSettled([
      this.checkDatabase(),
      this.checkRedis(),
      this.checkExternalServices(),
      this.checkDiskSpace(),
      this.checkMemory()
    ]);

    const status = this.aggregateHealthStatus(checks);

    return {
      status,
      timestamp: new Date(),
      checks: this.formatChecks(checks),
      uptime: process.uptime(),
      version: process.env.npm_package_version
    };
  }

  @Get('detailed')
  @UseGuards(AdminGuard)
  async getDetailedHealthStatus(): Promise<DetailedHealthResponse> {
    const [
      databaseStatus,
      redisStatus,
      queueStatus,
      metrics
    ] = await Promise.all([
      this.getDetailedDatabaseStatus(),
      this.getDetailedRedisStatus(),
      this.getQueueStatus(),
      this.getSystemMetrics()
    ]);

    return {
      overall: 'healthy',
      timestamp: new Date(),
      services: {
        database: databaseStatus,
        redis: redisStatus,
        queue: queueStatus
      },
      metrics,
      uptime: process.uptime()
    };
  }

  private async checkDatabase(): Promise<HealthCheck> {
    try {
      const result = await this.databaseService.query('SELECT 1');
      return {
        name: 'database',
        status: 'healthy',
        responseTime: result.responseTime,
        details: { connected: true }
      };
    } catch (error) {
      return {
        name: 'database',
        status: 'unhealthy',
        error: error.message,
        details: { connected: false }
      };
    }
  }

  private async checkRedis(): Promise<HealthCheck> {
    try {
      const start = Date.now();
      await this.redisService.ping();
      const responseTime = Date.now() - start;

      return {
        name: 'redis',
        status: 'healthy',
        responseTime,
        details: { connected: true }
      };
    } catch (error) {
      return {
        name: 'redis',
        status: 'unhealthy',
        error: error.message
      };
    }
  }

  private aggregateHealthStatus(checks: PromiseSettledResult<HealthCheck>[]): string {
    const unhealthyCount = checks.filter(
      check => check.status === 'fulfilled' && check.value.status === 'unhealthy'
    ).length;

    if (unhealthyCount === 0) {
      return 'healthy';
    } else if (unhealthyCount < checks.length / 2) {
      return 'degraded';
    } else {
      return 'unhealthy';
    }
  }
}
```

## å®šæœŸç»´æŠ¤è®¡åˆ’

### å‘¨ç»´æŠ¤ä»»åŠ¡

#### æ•°æ®åº“ç»´æŠ¤
```sql
-- scripts/weekly-maintenance.sql

-- 1. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
ANALYZE;

-- 2. æ¸…ç†è¿‡æœŸä¼šè¯
DELETE FROM chat_sessions
WHERE updated_at < NOW() - INTERVAL '30 days';

-- 3. æ¸…ç†è¿‡æœŸæ¶ˆæ¯
DELETE FROM messages
WHERE created_at < NOW() - INTERVAL '90 days'
AND session_id NOT IN (SELECT id FROM chat_sessions);

-- 4. é‡å»ºç´¢å¼•
REINDEX INDEX CONCURRENTLY idx_messages_created_at;
REINDEX INDEX CONCURRENTLY idx_sessions_user_id;

-- 5. æ£€æŸ¥æ•°æ®åº“å¤§å°
SELECT
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- 6. æ£€æŸ¥è¡¨ç»Ÿè®¡ä¿¡æ¯
SELECT
  schemaname,
  tablename,
  n_tup_ins,
  n_tup_upd,
  n_tup_del,
  n_live_tup,
  n_dead_tup
FROM pg_stat_user_tables;
```

#### åº”ç”¨ç¨‹åºæ¸…ç†
```bash
#!/bin/bash
# scripts/weekly-cleanup.sh

echo "ğŸ§¹ LLMChat å‘¨åº¦æ¸…ç† - $(date)"

# 1. æ¸…ç†æ—¥å¿—æ–‡ä»¶
echo "ğŸ“ æ¸…ç†æ—¥å¿—æ–‡ä»¶..."
find /var/log/llmchat -name "*.log" -mtime +7 -delete
find /var/log/llmchat -name "*.log.*" -mtime +7 -delete

# 2. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
echo "ğŸ—‚ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
find /tmp -name "llmchat-*" -mtime +1 -delete

# 3. æ¸…ç†ä¸Šä¼ æ–‡ä»¶
echo "ğŸ“ æ¸…ç†è¿‡æœŸä¸Šä¼ æ–‡ä»¶..."
find /var/uploads -name "*" -mtime +30 -delete

# 4. æ•°æ®åº“å¤‡ä»½
echo "ğŸ’¾ æ‰§è¡Œæ•°æ®åº“å¤‡ä»½..."
pg_dump llmchat > /backups/llmchat-$(date +%Y%m%d).sql

# 5. æ¸…ç†æ—§å¤‡ä»½
echo "ğŸ—‘ï¸ æ¸…ç†æ—§å¤‡ä»½..."
find /backups -name "llmchat-*.sql" -mtime +30 -delete

# 6. æ›´æ–°è½¯ä»¶åŒ…
echo "ğŸ“¦ æ›´æ–°è½¯ä»¶åŒ…..."
apt-get update && apt-get upgrade -y

echo "âœ… å‘¨åº¦æ¸…ç†å®Œæˆ"
```

### æœˆç»´æŠ¤ä»»åŠ¡

#### æ€§èƒ½åˆ†æ
```typescript
// scripts/performance-analysis.js
const fs = require('fs');
const path = require('path');

class PerformanceAnalyzer {
  constructor() {
    this.metricsDir = '/var/metrics/llmchat';
  }

  async analyzePerformance() {
    const currentMonth = new Date().toISOString().slice(0, 7);
    const metricsFile = path.join(this.metricsDir, `metrics-${currentMonth}.json`);

    try {
      const metrics = JSON.parse(fs.readFileSync(metricsFile, 'utf8'));

      const analysis = {
        averageResponseTime: this.calculateAverageResponseTime(metrics),
        errorRate: this.calculateErrorRate(metrics),
        throughput: this.calculateThroughput(metrics),
        memoryUsage: this.analyzeMemoryUsage(metrics),
        databasePerformance: this.analyzeDatabasePerformance(metrics)
      };

      this.generateReport(analysis);
      this.checkThresholds(analysis);

    } catch (error) {
      console.error('æ€§èƒ½åˆ†æå¤±è´¥:', error.message);
    }
  }

  calculateAverageResponseTime(metrics) {
    const responseTimes = metrics.map(m => m.responseTime).filter(t => t > 0);
    return responseTimes.reduce((sum, time) => sum + time, 0) / responseTimes.length;
  }

  calculateErrorRate(metrics) {
    const totalRequests = metrics.length;
    const errorRequests = metrics.filter(m => m.status >= 400).length;
    return (errorRequests / totalRequests) * 100;
  }

  checkThresholds(analysis) {
    const alerts = [];

    if (analysis.averageResponseTime > 500) {
      alerts.push({
        type: 'performance',
        message: `å¹³å‡å“åº”æ—¶é—´è¿‡é«˜: ${analysis.averageResponseTime}ms`,
        severity: 'warning'
      });
    }

    if (analysis.errorRate > 1) {
      alerts.push({
        type: 'error_rate',
        message: `é”™è¯¯ç‡è¿‡é«˜: ${analysis.errorRate}%`,
        severity: 'critical'
      });
    }

    if (analysis.memoryUsage.average > 80) {
      alerts.push({
        type: 'memory',
        message: `å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: ${analysis.memoryUsage.average}%`,
        severity: 'warning'
      });
    }

    if (alerts.length > 0) {
      this.sendAlerts(alerts);
    }
  }

  generateReport(analysis) {
    const report = `
# LLMChat æ€§èƒ½åˆ†ææŠ¥å‘Š - ${new Date().toISOString()}

## å“åº”æ—¶é—´
- å¹³å‡å“åº”æ—¶é—´: ${analysis.averageResponseTime.toFixed(2)}ms
- P95å“åº”æ—¶é—´: ${analysis.responseTime.p95}ms
- P99å“åº”æ—¶é—´: ${analysis.responseTime.p99}ms

## é”™è¯¯ç‡
- æ€»ä½“é”™è¯¯ç‡: ${analysis.errorRate.toFixed(2)}%
- 4xxé”™è¯¯: ${analysis.errors.clientError}æ¬¡
- 5xxé”™è¯¯: ${analysis.errors.serverError}æ¬¡

## ååé‡
- æ¯ç§’è¯·æ±‚æ•°: ${analysis.throughput.rps}
- æ¯æ—¥è¯·æ±‚æ•°: ${analysis.throughput.dailyRequests}

## èµ„æºä½¿ç”¨
- CPUä½¿ç”¨ç‡: ${analysis.cpuUsage.average}%
- å†…å­˜ä½¿ç”¨ç‡: ${analysis.memoryUsage.average}%
- ç£ç›˜ä½¿ç”¨ç‡: ${analysis.diskUsage.average}%

## æ•°æ®åº“æ€§èƒ½
- è¿æ¥æ•°: ${analysis.database.connections}
- æŸ¥è¯¢å¹³å‡æ—¶é—´: ${analysis.database.averageQueryTime}ms
- æ…¢æŸ¥è¯¢æ•°é‡: ${analysis.database.slowQueries}

## å»ºè®®
${this.generateRecommendations(analysis)}
    `;

    fs.writeFileSync(
      path.join(this.metricsDir, `performance-report-${new Date().toISOString().slice(0, 10)}.md`),
      report
    );
  }
}

// æ‰§è¡Œæ€§èƒ½åˆ†æ
const analyzer = new PerformanceAnalyzer();
analyzer.analyzePerformance();
```

## ç›‘æ§ç³»ç»Ÿ

### ç›‘æ§é…ç½®
```yaml
# monitoring/docker-compose.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: llmchat-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'

  grafana:
    image: grafana/grafana:latest
    container_name: llmchat-grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123

  alertmanager:
    image: prom/alertmanager:latest
    container_name: llmchat-alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager-data:/alertmanager

  node-exporter:
    image: prom/node-exporter:latest
    container_name: llmchat-node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'

volumes:
  prometheus-data:
  grafana-data:
  alertmanager-data:
```

### åº”ç”¨æŒ‡æ ‡æ”¶é›†
```typescript
// backend/src/metrics/metrics.service.ts
import { Injectable } from '@nestjs/common';
import { createPrometheusMetrics } from 'prom-client';

@Injectable()
export class MetricsService {
  private readonly metrics: ReturnType<typeof createPrometheusMetrics>;

  constructor() {
    this.metrics = createPrometheusMetrics({
      prefix: 'llmchat_',
      labels: ['method', 'route', 'status'],
    });

    this.setupCustomMetrics();
  }

  private setupCustomMetrics() {
    // HTTPè¯·æ±‚æŒ‡æ ‡
    this.httpRequestsTotal = new this.metrics.Counter({
      name: 'http_requests_total',
      help: 'HTTPè¯·æ±‚æ€»æ•°',
      labelNames: ['method', 'route', 'status_code'],
    });

    this.httpRequestDuration = new this.metrics.Histogram({
      name: 'http_request_duration_seconds',
      help: 'HTTPè¯·æ±‚æŒç»­æ—¶é—´',
      labelNames: ['method', 'route'],
      buckets: [0.1, 0.5, 1, 2, 5, 10],
    });

    // ä¸šåŠ¡æŒ‡æ ‡
    this.chatMessagesTotal = new this.metrics.Counter({
      name: 'chat_messages_total',
      help: 'èŠå¤©æ¶ˆæ¯æ€»æ•°',
      labelNames: ['agent_id', 'status'],
    });

    this.activeSessions = new this.metrics.Gauge({
      name: 'active_sessions_total',
      help: 'å½“å‰æ´»è·ƒä¼šè¯æ•°',
    });

    // ç³»ç»ŸæŒ‡æ ‡
    this.databaseConnections = new this.metrics.Gauge({
      name: 'database_connections_active',
      help: 'æ´»è·ƒæ•°æ®åº“è¿æ¥æ•°',
    });

    this.redisConnections = new this.metrics.Gauge({
      name: 'redis_connections_active',
      help: 'æ´»è·ƒRedisè¿æ¥æ•°',
    });
  }

  // è®°å½•HTTPè¯·æ±‚
  recordHttpRequest(method: string, route: string, statusCode: number, duration: number) {
    this.httpRequestsTotal.inc({ method, route, status_code: statusCode.toString() });
    this.httpRequestDuration.observe({ method, route }, duration / 1000);
  }

  // è®°å½•èŠå¤©æ¶ˆæ¯
  recordChatMessage(agentId: string, status: 'success' | 'error') {
    this.chatMessagesTotal.inc({ agent_id: agentId, status });
  }

  // æ›´æ–°æ´»è·ƒä¼šè¯æ•°
  updateActiveSessions(count: number) {
    this.activeSessions.set(count);
  }

  // æ›´æ–°æ•°æ®åº“è¿æ¥æ•°
  updateDatabaseConnections(count: number) {
    this.databaseConnections.set(count);
  }

  // è·å–æŒ‡æ ‡æ•°æ®
  async getMetrics() {
    return {
      httpRequestsTotal: await this.httpRequestsTotal.get(),
      httpRequestDuration: await this.httpRequestDuration.get(),
      chatMessagesTotal: await this.chatMessagesTotal.get(),
      activeSessions: await this.activeSessions.get(),
      databaseConnections: await this.databaseConnections.get(),
      redisConnections: await this.redisConnections.get(),
    };
  }
}
```

## æ•…éšœå¤„ç†æµç¨‹

### æ•…éšœæ£€æµ‹
```typescript
// backend/src/monitoring/fault-detection.service.ts
import { Injectable } from '@nestjs/common';
import { Cron } from '@nestjs/schedule';

@Injectable()
export class FaultDetectionService {
  private readonly faultThresholds = {
    errorRate: 0.05, // 5%
    responseTime: 2000, // 2ç§’
    memoryUsage: 0.9, // 90%
    diskUsage: 0.85, // 85%
  };

  constructor(
    private readonly metricsService: MetricsService,
    private readonly notificationService: NotificationService
  ) {}

  @Cron('*/5 * * * *') // æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
  async performHealthCheck() {
    const metrics = await this.metricsService.getMetrics();
    const faults = await this.detectFaults(metrics);

    if (faults.length > 0) {
      await this.handleFaults(faults);
    }
  }

  private async detectFaults(metrics: any): Promise<Fault[]> {
    const faults: Fault[] = [];

    // æ£€æŸ¥é”™è¯¯ç‡
    const errorRate = this.calculateErrorRate(metrics);
    if (errorRate > this.faultThresholds.errorRate) {
      faults.push({
        type: 'high_error_rate',
        severity: 'critical',
        message: `é”™è¯¯ç‡è¿‡é«˜: ${(errorRate * 100).toFixed(2)}%`,
        value: errorRate,
        threshold: this.faultThresholds.errorRate
      });
    }

    // æ£€æŸ¥å“åº”æ—¶é—´
    const avgResponseTime = this.calculateAverageResponseTime(metrics);
    if (avgResponseTime > this.faultThresholds.responseTime) {
      faults.push({
        type: 'slow_response',
        severity: 'warning',
        message: `å“åº”æ—¶é—´è¿‡æ…¢: ${avgResponseTime}ms`,
        value: avgResponseTime,
        threshold: this.faultThresholds.responseTime
      });
    }

    // æ£€æŸ¥å†…å­˜ä½¿ç”¨
    const memoryUsage = await this.getMemoryUsage();
    if (memoryUsage > this.faultThresholds.memoryUsage) {
      faults.push({
        type: 'high_memory_usage',
        severity: 'critical',
        message: `å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: ${(memoryUsage * 100).toFixed(2)}%`,
        value: memoryUsage,
        threshold: this.faultThresholds.memoryUsage
      });
    }

    return faults;
  }

  private async handleFaults(faults: Fault[]) {
    for (const fault of faults) {
      // è®°å½•æ•…éšœæ—¥å¿—
      console.error(`ç³»ç»Ÿæ•…éšœæ£€æµ‹åˆ°: ${fault.message}`);

      // å‘é€å‘Šè­¦é€šçŸ¥
      await this.notificationService.sendAlert({
        title: `LLMChat ç³»ç»Ÿå‘Šè­¦`,
        message: fault.message,
        severity: fault.severity,
        timestamp: new Date(),
        metadata: {
          type: fault.type,
          value: fault.value,
          threshold: fault.threshold
        }
      });

      // è‡ªåŠ¨æ¢å¤æªæ–½
      await this.attemptAutoRecovery(fault);
    }
  }

  private async attemptAutoRecovery(fault: Fault) {
    switch (fault.type) {
      case 'high_memory_usage':
        // è§¦å‘åƒåœ¾å›æ”¶
        if (global.gc) {
          global.gc();
        }
        break;

      case 'high_error_rate':
        // é‡å¯å—å½±å“çš„æœåŠ¡
        await this.restartAffectedServices();
        break;

      case 'slow_response':
        // å¢åŠ ç¼“å­˜æ¸…ç†é¢‘ç‡
        await this.increaseCacheCleanup();
        break;
    }
  }
}
```

### å‘Šè­¦é€šçŸ¥
```typescript
// backend/src/notification/notification.service.ts
@Injectable()
export class NotificationService {
  constructor(
    @Inject('EMAIL_SERVICE') private readonly emailService: EmailService,
    @Inject('SLACK_SERVICE') private readonly slackService: SlackService
  ) {}

  async sendAlert(alert: Alert) {
    const channels = this.getNotificationChannels(alert.severity);

    const notifications = channels.map(channel =>
      this.sendNotification(channel, alert)
    );

    await Promise.allSettled(notifications);
  }

  private async sendNotification(channel: string, alert: Alert) {
    switch (channel) {
      case 'email':
        await this.emailService.send({
          to: this.getAlertEmails(alert.severity),
          subject: `LLMChat å‘Šè­¦: ${alert.title}`,
          template: 'alert',
          data: alert
        });
        break;

      case 'slack':
        await this.slackService.sendMessage({
          channel: this.getSlackChannel(alert.severity),
          text: this.formatSlackMessage(alert)
        });
        break;

      case 'webhook':
        await this.sendWebhookAlert(alert);
        break;
    }
  }

  private getNotificationChannels(severity: string): string[] {
    switch (severity) {
      case 'critical':
        return ['email', 'slack', 'webhook'];
      case 'warning':
        return ['slack', 'webhook'];
      case 'info':
        return ['webhook'];
      default:
        return [];
    }
  }
}
```

## ç‰ˆæœ¬ç®¡ç†

### éƒ¨ç½²æµç¨‹
```bash
#!/bin/bash
# scripts/deploy.sh

set -e

VERSION=$1
ENVIRONMENT=${2:-production}

if [ -z "$VERSION" ]; then
    echo "é”™è¯¯: è¯·æä¾›ç‰ˆæœ¬å·"
    echo "ç”¨æ³•: $0 <version> [environment]"
    exit 1
fi

echo "ğŸš€ å¼€å§‹éƒ¨ç½² LLMChat v$VERSION åˆ° $ENVIRONMENT ç¯å¢ƒ"

# 1. å¤‡ä»½å½“å‰ç‰ˆæœ¬
echo "ğŸ’¾ å¤‡ä»½å½“å‰ç‰ˆæœ¬..."
./scripts/backup.sh

# 2. è¿è¡Œæµ‹è¯•
echo "ğŸ§ª è¿è¡Œæµ‹è¯•å¥—ä»¶..."
npm run test
npm run e2e:test

# 3. æ„å»ºæ–°ç‰ˆæœ¬
echo "ğŸ“¦ æ„å»ºæ–°ç‰ˆæœ¬..."
npm run build

# 4. æ•°æ®åº“è¿ç§»
echo "ğŸ—„ï¸ æ‰§è¡Œæ•°æ®åº“è¿ç§»..."
npm run migrate:up

# 5. éƒ¨ç½²åº”ç”¨
echo "ğŸš¢ éƒ¨ç½²åº”ç”¨..."
docker-compose -f docker-compose.$ENVIRONMENT.yml up -d

# 6. å¥åº·æ£€æŸ¥
echo "ğŸ¥ æ‰§è¡Œå¥åº·æ£€æŸ¥..."
./scripts/health-check.sh

# 7. éªŒè¯éƒ¨ç½²
echo "âœ… éªŒè¯éƒ¨ç½²..."
./scripts/verify-deployment.sh

echo "ğŸ‰ éƒ¨ç½²å®Œæˆï¼"
```

### ç‰ˆæœ¬å›æ»š
```bash
#!/bin/bash
# scripts/rollback.sh

set -e

PREVIOUS_VERSION=$1
ENVIRONMENT=${2:-production}

if [ -z "$PREVIOUS_VERSION" ]; then
    echo "é”™è¯¯: è¯·æä¾›å›æ»šç‰ˆæœ¬"
    echo "ç”¨æ³•: $0 <version> [environment]"
    exit 1
fi

echo "ğŸ”„ å¼€å§‹å›æ»šåˆ°ç‰ˆæœ¬ $PREVIOUS_VERSION"

# 1. åœæ­¢å½“å‰æœåŠ¡
echo "â¹ï¸ åœæ­¢å½“å‰æœåŠ¡..."
docker-compose -f docker-compose.$ENVIRONMENT.yml down

# 2. åˆ‡æ¢åˆ°æŒ‡å®šç‰ˆæœ¬
echo "ğŸ“¦ åˆ‡æ¢åˆ°ç‰ˆæœ¬ $PREVIOUS_VERSION..."
git checkout $PREVIOUS_VERSION
npm run build

# 3. å¯åŠ¨æœåŠ¡
echo "ğŸš¢ å¯åŠ¨æœåŠ¡..."
docker-compose -f docker-compose.$ENVIRONMENT.yml up -d

# 4. æ•°æ®åº“å›æ»šï¼ˆå¦‚æœéœ€è¦ï¼‰
read -p "æ˜¯å¦éœ€è¦å›æ»šæ•°æ®åº“ï¼Ÿ(y/n): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "ğŸ—„ï¸ å›æ»šæ•°æ®åº“..."
    npm run migrate:down
fi

# 5. éªŒè¯å›æ»š
echo "âœ… éªŒè¯å›æ»š..."
./scripts/health-check.sh

echo "ğŸ‰ å›æ»šå®Œæˆï¼"
```

## å¤‡ä»½ç­–ç•¥

### è‡ªåŠ¨åŒ–å¤‡ä»½
```bash
#!/bin/bash
# scripts/backup.sh

BACKUP_DIR="/backups/llmchat"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

echo "ğŸ“¦ å¼€å§‹å¤‡ä»½ - $(date)"

# åˆ›å»ºå¤‡ä»½ç›®å½•
mkdir -p $BACKUP_DIR

# 1. æ•°æ®åº“å¤‡ä»½
echo "ğŸ—„ï¸ å¤‡ä»½æ•°æ®åº“..."
pg_dump -h localhost -U postgres llmchat > $BACKUP_DIR/database_$DATE.sql

# 2. åº”ç”¨æ–‡ä»¶å¤‡ä»½
echo "ğŸ“ å¤‡ä»½åº”ç”¨æ–‡ä»¶..."
tar -czf $BACKUP_DIR/application_$DATE.tar.gz \
    /opt/llmchat \
    --exclude=node_modules \
    --exclude=dist \
    --exclude=.git

# 3. é…ç½®æ–‡ä»¶å¤‡ä»½
echo "âš™ï¸ å¤‡ä»½é…ç½®æ–‡ä»¶..."
tar -czf $BACKUP_DIR/config_$DATE.tar.gz \
    /etc/llmchat \
    /opt/llmchat/.env

# 4. ä¸Šä¼ æ–‡ä»¶å¤‡ä»½
echo "ğŸ“¤ å¤‡ä»½ä¸Šä¼ æ–‡ä»¶..."
tar -czf $BACKUP_DIR/uploads_$DATE.tar.gz \
    /var/uploads/llmchat

# 5. æ¸…ç†æ—§å¤‡ä»½
echo "ğŸ—‘ï¸ æ¸…ç†æ—§å¤‡ä»½..."
find $BACKUP_DIR -name "*.sql" -mtime +$RETENTION_DAYS -delete
find $BACKUP_DIR -name "*.tar.gz" -mtime +$RETENTION_DAYS -delete

# 6. éªŒè¯å¤‡ä»½
echo "âœ… éªŒè¯å¤‡ä»½..."
for file in $BACKUP_DIR/*_$DATE.*; do
    if [ -s "$file" ]; then
        echo "âœ… å¤‡ä»½æ–‡ä»¶æœ‰æ•ˆ: $file"
    else
        echo "âŒ å¤‡ä»½æ–‡ä»¶æ— æ•ˆ: $file"
    fi
done

echo "âœ… å¤‡ä»½å®Œæˆ - $(date)"
```

### æ¢å¤æµç¨‹
```bash
#!/bin/bash
# scripts/restore.sh

BACKUP_FILE=$1
RESTORE_TYPE=$2

if [ -z "$BACKUP_FILE" ] || [ -z "$RESTORE_TYPE" ]; then
    echo "é”™è¯¯: è¯·æä¾›å¤‡ä»½æ–‡ä»¶å’Œæ¢å¤ç±»å‹"
    echo "ç”¨æ³•: $0 <backup_file> <type>"
    echo "ç±»å‹: database | application | config | uploads"
    exit 1
fi

echo "ğŸ”„ å¼€å§‹æ¢å¤ - $(date)"

case $RESTORE_TYPE in
    "database")
        echo "ğŸ—„ï¸ æ¢å¤æ•°æ®åº“..."
        psql -h localhost -U postgres -d llmchat < $BACKUP_FILE
        ;;

    "application")
        echo "ğŸ“¦ æ¢å¤åº”ç”¨æ–‡ä»¶..."
        tar -xzf $BACKUP_FILE -C /
        ;;

    "config")
        echo "âš™ï¸ æ¢å¤é…ç½®æ–‡ä»¶..."
        tar -xzf $BACKUP_FILE -C /
        ;;

    "uploads")
        echo "ğŸ“¤ æ¢å¤ä¸Šä¼ æ–‡ä»¶..."
        tar -xzf $BACKUP_FILE -C /
        ;;

    *)
        echo "é”™è¯¯: ä¸æ”¯æŒçš„æ¢å¤ç±»å‹: $RESTORE_TYPE"
        exit 1
        ;;
esac

echo "âœ… æ¢å¤å®Œæˆ - $(date)"
```

## æ€§èƒ½è°ƒä¼˜

### æ•°æ®åº“ä¼˜åŒ–
```sql
-- scripts/database-optimization.sql

-- 1. åˆ›å»ºå¿…è¦çš„ç´¢å¼•
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_messages_session_created
ON messages(session_id, created_at);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_sessions_user_updated
ON chat_sessions(user_id, updated_at);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_agents_provider_active
ON agents(provider, is_active);

-- 2. ä¼˜åŒ–æ…¢æŸ¥è¯¢
EXPLAIN ANALYZE
SELECT m.*, s.user_id
FROM messages m
JOIN chat_sessions s ON m.session_id = s.id
WHERE s.user_id = 'user-id'
ORDER BY m.created_at DESC
LIMIT 50;

-- 3. æ›´æ–°è¡¨ç»Ÿè®¡ä¿¡æ¯
ANALYZE messages;
ANALYZE chat_sessions;
ANALYZE agents;

-- 4. æ£€æŸ¥è¡¨ç¢ç‰‡åŒ–
SELECT
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
  pg_stat_get_dead_tuples(c.oid) AS dead_tuples
FROM pg_class c
JOIN pg_namespace n ON n.oid = c.relnamespace
WHERE n.nspname = 'public'
ORDER BY pg_stat_get_dead_tuples(c.oid) DESC;

-- 5. æ¸…ç†æ­»å…ƒç»„
VACUUM ANALYZE messages;
VACUUM ANALYZE chat_sessions;
VACUUM ANALYZE agents;
```

### åº”ç”¨ä¼˜åŒ–
```typescript
// scripts/performance-optimization.ts

class PerformanceOptimizer {
  async optimizeApplication() {
    // 1. ç¼“å­˜ä¼˜åŒ–
    await this.optimizeCache();

    // 2. æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–
    await this.optimizeDatabasePool();

    // 3. å†…å­˜ä½¿ç”¨ä¼˜åŒ–
    await this.optimizeMemoryUsage();

    // 4. å¹¶å‘å¤„ç†ä¼˜åŒ–
    await this.optimizeConcurrency();
  }

  private async optimizeCache() {
    // Redisç¼“å­˜ä¼˜åŒ–
    const redisConfig = {
      maxRetriesPerRequest: 3,
      retryDelayOnFailover: 100,
      enableOfflineQueue: false,
      lazyConnect: true
    };

    // ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
    const cacheStrategies = {
      'agents': { ttl: 3600, maxSize: 1000 },
      'sessions': { ttl: 1800, maxSize: 5000 },
      'messages': { ttl: 300, maxSize: 10000 }
    };
  }

  private async optimizeDatabasePool() {
    const poolConfig = {
      min: 2,
      max: 10,
      acquireTimeoutMillis: 30000,
      createTimeoutMillis: 30000,
      destroyTimeoutMillis: 5000,
      idleTimeoutMillis: 30000,
      reapIntervalMillis: 1000,
      createRetryIntervalMillis: 200
    };

    return poolConfig;
  }

  private async optimizeMemoryUsage() {
    // Node.js å†…å­˜ä¼˜åŒ–
    if (global.gc) {
      // æ‰‹åŠ¨è§¦å‘åƒåœ¾å›æ”¶
      global.gc();
    }

    // å†…å­˜ç›‘æ§
    const memUsage = process.memoryUsage();
    const heapUsed = memUsage.heapUsed / 1024 / 1024; // MB
    const heapTotal = memUsage.heapTotal / 1024 / 1024; // MB

    if (heapUsed / heapTotal > 0.9) {
      console.warn('å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®å¢åŠ å†…å­˜æˆ–ä¼˜åŒ–ä»£ç ');
    }
  }

  private async optimizeConcurrency() {
    // å¹¶å‘é™åˆ¶
    const concurrencyLimits = {
      'chat_requests': 100,
      'file_uploads': 10,
      'database_queries': 50
    };

    // é˜Ÿåˆ—é…ç½®
    const queueConfig = {
      redis: {
        maxConcurrency: 10,
        attempts: 3,
        backoff: 'exponential'
      }
    };

    return { concurrencyLimits, queueConfig };
  }
}

// æ‰§è¡Œæ€§èƒ½ä¼˜åŒ–
const optimizer = new PerformanceOptimizer();
optimizer.optimizeApplication();
```

---

*æœ€åæ›´æ–°: 2025-10-18*
*æ–‡æ¡£ç‰ˆæœ¬: v1.0*
*ç»´æŠ¤è€…: è¿ç»´å›¢é˜Ÿ*