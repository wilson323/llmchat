# é«˜å¯ç”¨æ€§ç­–ç•¥ - å…¨å±€é¡¹ç›®ä¼˜åŒ–

## ğŸ¯ é«˜å¯ç”¨æ€§ç›®æ ‡

**å¯ç”¨æ€§æŒ‡æ ‡**: 99.9% (æ¯æœˆåœæœºæ—¶é—´ < 43åˆ†é’Ÿ)  
**RTO** (æ¢å¤æ—¶é—´ç›®æ ‡): < 5åˆ†é’Ÿ  
**RPO** (æ¢å¤ç‚¹ç›®æ ‡): < 1åˆ†é’Ÿ  

---

## ğŸ”’ æ ¸å¿ƒé«˜å¯ç”¨ç­–ç•¥

### 1. æœåŠ¡å±‚é«˜å¯ç”¨

#### 1.1 é›¶åœæœºéƒ¨ç½²
```bash
# ä½¿ç”¨PM2æ»šåŠ¨é‡å¯
pm2 reload backend --update-env

# ä½¿ç”¨K8sæ»šåŠ¨æ›´æ–°
kubectl rollout restart deployment/llmchat-backend

# è“ç»¿éƒ¨ç½²ç­–ç•¥
# - ä¿ç•™æ—§ç‰ˆæœ¬è¿è¡Œ
# - æ–°ç‰ˆæœ¬é€šè¿‡å¥åº·æ£€æŸ¥ååˆ‡æµé‡
# - éªŒè¯æ— é—®é¢˜åä¸‹çº¿æ—§ç‰ˆæœ¬
```

#### 1.2 å¥åº·æ£€æŸ¥å¢å¼º
```typescript
// backend/src/routes/health.ts (å¢å¼ºç‰ˆ)
export const healthCheck = async (req: Request, res: Response) => {
  const health = {
    status: 'healthy',
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    checks: {
      database: 'unknown',
      redis: 'unknown',
      memory: 'unknown',
    },
  };

  try {
    // 1. æ•°æ®åº“å¥åº·æ£€æŸ¥ (è¶…æ—¶2ç§’)
    const dbStart = Date.now();
    await Promise.race([
      pool.query('SELECT 1'),
      new Promise((_, reject) => 
        setTimeout(() => reject(new Error('DB timeout')), 2000)
      ),
    ]);
    health.checks.database = 'healthy';
    
    // 2. Rediså¥åº·æ£€æŸ¥ (è¶…æ—¶2ç§’)
    const redisStart = Date.now();
    await Promise.race([
      redis.ping(),
      new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Redis timeout')), 2000)
      ),
    ]);
    health.checks.redis = 'healthy';
    
    // 3. å†…å­˜æ£€æŸ¥ (>80%å‘Šè­¦)
    const memUsage = process.memoryUsage();
    const memPercent = (memUsage.heapUsed / memUsage.heapTotal) * 100;
    health.checks.memory = memPercent < 80 ? 'healthy' : 'warning';
    
    // æ‰€æœ‰æ£€æŸ¥é€šè¿‡è¿”å›200
    res.status(200).json(health);
  } catch (error) {
    // ä»»ä½•æ£€æŸ¥å¤±è´¥è¿”å›503
    health.status = 'unhealthy';
    res.status(503).json(health);
  }
};
```

#### 1.3 ä¼˜é›…å…³é—­æœºåˆ¶
```typescript
// backend/src/index.ts (ä¼˜é›…å…³é—­)
let isShuttingDown = false;

process.on('SIGTERM', gracefulShutdown);
process.on('SIGINT', gracefulShutdown);

async function gracefulShutdown() {
  if (isShuttingDown) return;
  isShuttingDown = true;
  
  logger.info('Graceful shutdown initiated...');
  
  // 1. åœæ­¢æ¥å—æ–°è¯·æ±‚ (è¿”å›503)
  server.close(() => {
    logger.info('HTTP server closed');
  });
  
  // 2. ç­‰å¾…ç°æœ‰è¯·æ±‚å®Œæˆ (æœ€å¤š30ç§’)
  await Promise.race([
    waitForActiveRequests(),
    new Promise(resolve => setTimeout(resolve, 30000)),
  ]);
  
  // 3. å…³é—­æ•°æ®åº“è¿æ¥
  await pool.end();
  logger.info('Database connections closed');
  
  // 4. å…³é—­Redisè¿æ¥
  await redis.quit();
  logger.info('Redis connections closed');
  
  // 5. æ¸…ç†å®šæ—¶ä»»åŠ¡
  clearInterval(metricsInterval);
  
  logger.info('Graceful shutdown completed');
  process.exit(0);
}

// ä¸­é—´ä»¶ï¼šæ‹’ç»å…³é—­æœŸé—´çš„æ–°è¯·æ±‚
app.use((req, res, next) => {
  if (isShuttingDown) {
    res.set('Connection', 'close');
    return res.status(503).json({
      code: 'SERVICE_UNAVAILABLE',
      message: 'Server is shutting down',
    });
  }
  next();
});
```

---

### 2. æ•°æ®å±‚é«˜å¯ç”¨

#### 2.1 PostgreSQLè¿æ¥æ± ä¼˜åŒ–
```typescript
// backend/src/utils/db.ts (é«˜å¯ç”¨é…ç½®)
export const pool = new Pool({
  host: EnvManager.getInstance().get('DB_HOST'),
  port: parseInt(EnvManager.getInstance().get('DB_PORT', '5432')),
  user: EnvManager.getInstance().get('DB_USER'),
  password: EnvManager.getInstance().getRequired('DB_PASSWORD'),
  database: EnvManager.getInstance().get('DB_NAME'),
  
  // è¿æ¥æ± é…ç½® (é«˜å¯ç”¨)
  min: 5,                    // æœ€å°è¿æ¥æ•° (ä¿æŒçƒ­è¿æ¥)
  max: 20,                   // æœ€å¤§è¿æ¥æ•° (é˜²æ­¢è€—å°½)
  idleTimeoutMillis: 30000,  // ç©ºé—²è¿æ¥è¶…æ—¶30ç§’
  connectionTimeoutMillis: 5000, // è¿æ¥è¶…æ—¶5ç§’
  
  // è¿æ¥é‡è¯•
  maxUses: 7500,             // å•è¿æ¥æœ€å¤§ä½¿ç”¨æ¬¡æ•° (é˜²æ­¢å†…å­˜æ³„æ¼)
  
  // å¥åº·æ£€æŸ¥
  allowExitOnIdle: false,    // ç¦æ­¢ç©ºé—²æ—¶é€€å‡º
});

// è¿æ¥æ± ç›‘æ§
pool.on('connect', (client) => {
  logger.debug('New database connection established');
});

pool.on('error', (err, client) => {
  logger.error('Database pool error', { error: err });
  // è§¦å‘å‘Šè­¦ (é›†æˆç›‘æ§ç³»ç»Ÿ)
  alertService.send('Database pool error', err);
});

pool.on('remove', (client) => {
  logger.debug('Database connection removed from pool');
});

// å®šæœŸæ£€æŸ¥è¿æ¥æ± å¥åº·
setInterval(async () => {
  try {
    const { totalCount, idleCount, waitingCount } = pool;
    
    if (waitingCount > 5) {
      logger.warn('High database connection wait queue', {
        totalCount,
        idleCount,
        waitingCount,
      });
    }
    
    // æµ‹è¯•è¿æ¥
    await pool.query('SELECT 1');
  } catch (error) {
    logger.error('Database health check failed', { error });
  }
}, 60000); // æ¯åˆ†é’Ÿæ£€æŸ¥
```

#### 2.2 æ•°æ®åº“æŸ¥è¯¢è¶…æ—¶ä¸é‡è¯•
```typescript
// backend/src/utils/db.ts (æŸ¥è¯¢åŒ…è£…å™¨)
export async function queryWithRetry<T>(
  sql: string,
  params: any[],
  options: { maxRetries?: number; timeout?: number } = {}
): Promise<QueryResult<T>> {
  const { maxRetries = 3, timeout = 5000 } = options;
  
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      // è®¾ç½®æŸ¥è¯¢è¶…æ—¶
      const client = await pool.connect();
      
      try {
        await client.query('SET statement_timeout = $1', [timeout]);
        const result = await client.query<T>(sql, params);
        return result;
      } finally {
        client.release();
      }
    } catch (error: any) {
      const isRetriable = 
        error.code === 'ECONNRESET' ||  // è¿æ¥é‡ç½®
        error.code === '57P01' ||        // ç®¡ç†å‘˜å…³é—­
        error.code === '57P03';          // æ— æ³•è¿æ¥
      
      if (attempt < maxRetries && isRetriable) {
        logger.warn(`Query retry ${attempt}/${maxRetries}`, { error });
        await sleep(Math.pow(2, attempt) * 100); // æŒ‡æ•°é€€é¿
        continue;
      }
      
      throw error;
    }
  }
  
  throw new Error('Query failed after max retries');
}
```

#### 2.3 äº‹åŠ¡é«˜å¯ç”¨
```typescript
// backend/src/utils/db.ts (äº‹åŠ¡åŒ…è£…å™¨)
export async function withTransaction<T>(
  callback: (client: PoolClient) => Promise<T>
): Promise<T> {
  const client = await pool.connect();
  
  try {
    await client.query('BEGIN');
    const result = await callback(client);
    await client.query('COMMIT');
    return result;
  } catch (error) {
    await client.query('ROLLBACK');
    logger.error('Transaction rollback', { error });
    throw error;
  } finally {
    client.release();
  }
}
```

---

### 3. ç¼“å­˜å±‚é«˜å¯ç”¨

#### 3.1 Redisé«˜å¯ç”¨é…ç½®
```typescript
// backend/src/utils/redis.ts (é«˜å¯ç”¨é…ç½®)
import Redis from 'ioredis';

export const redis = new Redis({
  host: EnvManager.getInstance().get('REDIS_HOST', 'localhost'),
  port: parseInt(EnvManager.getInstance().get('REDIS_PORT', '6379')),
  password: EnvManager.getInstance().get('REDIS_PASSWORD'),
  db: parseInt(EnvManager.getInstance().get('REDIS_DB', '0')),
  
  // é«˜å¯ç”¨é…ç½®
  retryStrategy: (times: number) => {
    const delay = Math.min(times * 50, 2000); // æœ€å¤§2ç§’
    logger.warn(`Redis retry attempt ${times}, delay ${delay}ms`);
    return delay;
  },
  
  maxRetriesPerRequest: 3,      // æ¯è¯·æ±‚æœ€å¤§é‡è¯•3æ¬¡
  enableOfflineQueue: true,      // ç¦»çº¿æ—¶é˜Ÿåˆ—ç¼“å­˜
  connectTimeout: 10000,         // è¿æ¥è¶…æ—¶10ç§’
  
  // è‡ªåŠ¨é‡è¿
  autoResubscribe: true,
  autoResendUnfulfilledCommands: true,
});

// Redisäº‹ä»¶ç›‘å¬
redis.on('connect', () => {
  logger.info('Redis connected');
});

redis.on('ready', () => {
  logger.info('Redis ready');
});

redis.on('error', (err) => {
  logger.error('Redis error', { error: err });
});

redis.on('close', () => {
  logger.warn('Redis connection closed');
});

redis.on('reconnecting', () => {
  logger.info('Redis reconnecting...');
});

// Redisé™çº§ç­–ç•¥ (å†…å­˜ç¼“å­˜)
class CacheService {
  private memoryCache = new Map<string, { value: any; expiry: number }>();
  
  async get(key: string): Promise<any> {
    try {
      // å°è¯•ä»Redisè·å–
      const value = await redis.get(key);
      return value ? JSON.parse(value) : null;
    } catch (error) {
      logger.warn('Redis get failed, fallback to memory cache', { error });
      
      // é™çº§åˆ°å†…å­˜ç¼“å­˜
      const cached = this.memoryCache.get(key);
      if (cached && cached.expiry > Date.now()) {
        return cached.value;
      }
      return null;
    }
  }
  
  async set(key: string, value: any, ttl: number = 3600): Promise<void> {
    try {
      // å†™å…¥Redis
      await redis.setex(key, ttl, JSON.stringify(value));
      
      // åŒæ—¶å†™å…¥å†…å­˜ç¼“å­˜ (åŒå†™)
      this.memoryCache.set(key, {
        value,
        expiry: Date.now() + ttl * 1000,
      });
    } catch (error) {
      logger.warn('Redis set failed, using memory cache only', { error });
      
      // é™çº§åˆ°å†…å­˜ç¼“å­˜
      this.memoryCache.set(key, {
        value,
        expiry: Date.now() + ttl * 1000,
      });
    }
  }
  
  // å®šæœŸæ¸…ç†è¿‡æœŸå†…å­˜ç¼“å­˜
  startCleanup() {
    setInterval(() => {
      const now = Date.now();
      for (const [key, cached] of this.memoryCache.entries()) {
        if (cached.expiry <= now) {
          this.memoryCache.delete(key);
        }
      }
    }, 60000); // æ¯åˆ†é’Ÿæ¸…ç†
  }
}

export const cacheService = new CacheService();
cacheService.startCleanup();
```

#### 3.2 Rate Limiteré™çº§
```typescript
// backend/src/middleware/rateLimiter.ts (é«˜å¯ç”¨ç‰ˆæœ¬)
import { RateLimiterRedis, RateLimiterMemory } from 'rate-limiter-flexible';

let rateLimiter: RateLimiterRedis | RateLimiterMemory;
let isRedisFailed = false;

export function createRateLimiter() {
  const envManager = EnvManager.getInstance();
  
  try {
    // ä¼˜å…ˆä½¿ç”¨Redis
    rateLimiter = new RateLimiterRedis({
      storeClient: redis,
      keyPrefix: 'rl',
      points: parseInt(envManager.get('RATE_LIMIT_POINTS', '100')),
      duration: parseInt(envManager.get('RATE_LIMIT_DURATION', '60')),
      blockDuration: parseInt(envManager.get('RATE_LIMIT_BLOCK_DURATION', '60')),
    });
    
    logger.info('Rate limiter using Redis');
  } catch (error) {
    logger.warn('Redis rate limiter failed, fallback to memory', { error });
    isRedisFailed = true;
    
    // é™çº§åˆ°å†…å­˜ç‰ˆæœ¬
    rateLimiter = new RateLimiterMemory({
      points: parseInt(envManager.get('RATE_LIMIT_POINTS', '100')),
      duration: parseInt(envManager.get('RATE_LIMIT_DURATION', '60')),
      blockDuration: parseInt(envManager.get('RATE_LIMIT_BLOCK_DURATION', '60')),
    });
    
    logger.info('Rate limiter using Memory (degraded mode)');
  }
  
  return async (req: Request, res: Response, next: NextFunction) => {
    const key = req.ip || 'unknown';
    
    try {
      await rateLimiter.consume(key);
      next();
    } catch (error: any) {
      if (error.msBeforeNext) {
        res.set('Retry-After', String(Math.round(error.msBeforeNext / 1000)));
        res.status(429).json({
          code: 'TOO_MANY_REQUESTS',
          message: 'Too many requests, please try again later',
        });
      } else {
        // Rate limiteræœ¬èº«å¤±è´¥ï¼Œæ”¾è¡Œè¯·æ±‚ (é«˜å¯ç”¨ä¼˜å…ˆ)
        logger.error('Rate limiter error, allowing request', { error });
        next();
      }
    }
  };
}
```

---

### 4. å¤–éƒ¨æœåŠ¡è°ƒç”¨é«˜å¯ç”¨

#### 4.1 ç†”æ–­å™¨æ¨¡å¼
```typescript
// backend/src/utils/circuitBreaker.ts (æ–°å¢)
export class CircuitBreaker {
  private failures = 0;
  private successCount = 0;
  private lastFailureTime = 0;
  private state: 'CLOSED' | 'OPEN' | 'HALF_OPEN' = 'CLOSED';
  
  constructor(
    private threshold: number = 5,          // å¤±è´¥é˜ˆå€¼
    private timeout: number = 60000,        // ç†”æ–­è¶…æ—¶60ç§’
    private successThreshold: number = 2    // åŠå¼€çŠ¶æ€æˆåŠŸæ¬¡æ•°
  ) {}
  
  async execute<T>(fn: () => Promise<T>): Promise<T> {
    // ç†”æ–­å™¨æ‰“å¼€ï¼Œç›´æ¥æ‹’ç»
    if (this.state === 'OPEN') {
      if (Date.now() - this.lastFailureTime > this.timeout) {
        this.state = 'HALF_OPEN';
        this.successCount = 0;
        logger.info('Circuit breaker entering HALF_OPEN state');
      } else {
        throw new Error('Circuit breaker is OPEN');
      }
    }
    
    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }
  
  private onSuccess() {
    this.failures = 0;
    
    if (this.state === 'HALF_OPEN') {
      this.successCount++;
      if (this.successCount >= this.successThreshold) {
        this.state = 'CLOSED';
        logger.info('Circuit breaker closed');
      }
    }
  }
  
  private onFailure() {
    this.failures++;
    this.lastFailureTime = Date.now();
    
    if (this.failures >= this.threshold) {
      this.state = 'OPEN';
      logger.warn(`Circuit breaker opened after ${this.failures} failures`);
    }
  }
  
  getState() {
    return {
      state: this.state,
      failures: this.failures,
      successCount: this.successCount,
    };
  }
}
```

#### 4.2 FastGPT APIè°ƒç”¨é«˜å¯ç”¨
```typescript
// backend/src/services/ChatProxyService.ts (é«˜å¯ç”¨å¢å¼º)
export class FastGPTProxy {
  private circuitBreaker = new CircuitBreaker(5, 60000, 2);
  
  async sendMessage(options: ChatOptions): Promise<ChatResponse> {
    return this.circuitBreaker.execute(async () => {
      // è®¾ç½®è¶…æ—¶
      const controller = new AbortController();
      const timeout = setTimeout(() => controller.abort(), 30000);
      
      try {
        const response = await fetch(this.endpoint, {
          method: 'POST',
          headers: this.getHeaders(),
          body: JSON.stringify(this.buildRequest(options)),
          signal: controller.signal,
        });
        
        if (!response.ok) {
          throw new ApiError(response.status, 'FASTGPT_ERROR', 'FastGPT request failed');
        }
        
        return await response.json();
      } finally {
        clearTimeout(timeout);
      }
    });
  }
}
```

---

### 5. ç›‘æ§ä¸å‘Šè­¦

#### 5.1 å®æ—¶ç›‘æ§æŒ‡æ ‡
```typescript
// backend/src/utils/metrics.ts (æ–°å¢)
export class MetricsCollector {
  private metrics = {
    requests: { total: 0, success: 0, error: 0 },
    latency: { sum: 0, count: 0, p95: 0 },
    database: { connections: 0, queries: 0, errors: 0 },
    redis: { hits: 0, misses: 0, errors: 0 },
  };
  
  recordRequest(success: boolean, latency: number) {
    this.metrics.requests.total++;
    if (success) {
      this.metrics.requests.success++;
    } else {
      this.metrics.requests.error++;
    }
    
    this.metrics.latency.sum += latency;
    this.metrics.latency.count++;
  }
  
  recordDatabaseQuery(success: boolean) {
    this.metrics.database.queries++;
    if (!success) {
      this.metrics.database.errors++;
    }
  }
  
  recordCacheHit(hit: boolean) {
    if (hit) {
      this.metrics.redis.hits++;
    } else {
      this.metrics.redis.misses++;
    }
  }
  
  getMetrics() {
    return {
      ...this.metrics,
      latency: {
        ...this.metrics.latency,
        avg: this.metrics.latency.sum / this.metrics.latency.count,
      },
      successRate: (this.metrics.requests.success / this.metrics.requests.total) * 100,
      cacheHitRate: (this.metrics.redis.hits / (this.metrics.redis.hits + this.metrics.redis.misses)) * 100,
    };
  }
  
  // æš´éœ²Prometheusæ ¼å¼æŒ‡æ ‡
  getPrometheusMetrics() {
    const metrics = this.getMetrics();
    return `
# HELP http_requests_total Total HTTP requests
# TYPE http_requests_total counter
http_requests_total{status="success"} ${metrics.requests.success}
http_requests_total{status="error"} ${metrics.requests.error}

# HELP http_request_latency_avg Average request latency
# TYPE http_request_latency_avg gauge
http_request_latency_avg ${metrics.latency.avg}

# HELP db_queries_total Total database queries
# TYPE db_queries_total counter
db_queries_total ${metrics.database.queries}

# HELP cache_hit_rate Cache hit rate percentage
# TYPE cache_hit_rate gauge
cache_hit_rate ${metrics.cacheHitRate}
`.trim();
  }
}

export const metricsCollector = new MetricsCollector();

// æš´éœ²æŒ‡æ ‡ç«¯ç‚¹
app.get('/metrics', (req, res) => {
  res.set('Content-Type', 'text/plain');
  res.send(metricsCollector.getPrometheusMetrics());
});
```

#### 5.2 å‘Šè­¦è§„åˆ™
```typescript
// backend/src/utils/alerting.ts (æ–°å¢)
export class AlertService {
  private alerts: Array<{ level: string; message: string; timestamp: Date }> = [];
  
  async send(message: string, error?: Error, level: 'warning' | 'critical' = 'warning') {
    const alert = {
      level,
      message,
      timestamp: new Date(),
      error: error?.message,
      stack: error?.stack,
    };
    
    this.alerts.push(alert);
    logger[level === 'critical' ? 'error' : 'warn']('Alert triggered', alert);
    
    // é›†æˆå¤–éƒ¨å‘Šè­¦ç³»ç»Ÿ (å¯é€‰)
    // await this.sendToSlack(alert);
    // await this.sendToEmail(alert);
    // await this.sendToPagerDuty(alert);
  }
  
  getRecentAlerts(minutes: number = 60) {
    const cutoff = new Date(Date.now() - minutes * 60 * 1000);
    return this.alerts.filter(a => a.timestamp > cutoff);
  }
}

export const alertService = new AlertService();

// è‡ªåŠ¨ç›‘æ§ä¸å‘Šè­¦
setInterval(() => {
  const metrics = metricsCollector.getMetrics();
  
  // é”™è¯¯ç‡å‘Šè­¦ (>5%)
  if ((metrics.requests.error / metrics.requests.total) > 0.05) {
    alertService.send('High error rate detected', undefined, 'critical');
  }
  
  // å¹³å‡å»¶è¿Ÿå‘Šè­¦ (>1000ms)
  if (metrics.latency.avg > 1000) {
    alertService.send('High latency detected', undefined, 'warning');
  }
  
  // æ•°æ®åº“é”™è¯¯ç‡å‘Šè­¦ (>1%)
  if ((metrics.database.errors / metrics.database.queries) > 0.01) {
    alertService.send('Database error rate high', undefined, 'critical');
  }
  
  // ç¼“å­˜å‘½ä¸­ç‡å‘Šè­¦ (<50%)
  if (metrics.cacheHitRate < 50) {
    alertService.send('Low cache hit rate', undefined, 'warning');
  }
}, 60000); // æ¯åˆ†é’Ÿæ£€æŸ¥
```

---

## ğŸ“Š é«˜å¯ç”¨æ£€æŸ¥æ¸…å•

### éƒ¨ç½²å‰æ£€æŸ¥
- [ ] å¥åº·æ£€æŸ¥ç«¯ç‚¹æ­£å¸¸å“åº”
- [ ] æ•°æ®åº“è¿æ¥æ± é…ç½®åˆç†
- [ ] Redisé™çº§ç­–ç•¥å·²éªŒè¯
- [ ] ä¼˜é›…å…³é—­æœºåˆ¶å·²æµ‹è¯•
- [ ] ç†”æ–­å™¨é˜ˆå€¼å·²è°ƒä¼˜
- [ ] ç›‘æ§æŒ‡æ ‡å·²æ¥å…¥
- [ ] å‘Šè­¦è§„åˆ™å·²é…ç½®
- [ ] å¤‡ä»½æ¢å¤æµç¨‹å·²æ¼”ç»ƒ

### è¿è¡Œæ—¶ç›‘æ§
- [ ] æœåŠ¡å“åº”æ—¶é—´ <500ms (P95)
- [ ] é”™è¯¯ç‡ <1%
- [ ] æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡ <80%
- [ ] Rediså‘½ä¸­ç‡ >70%
- [ ] å†…å­˜ä½¿ç”¨ç‡ <80%
- [ ] CPUä½¿ç”¨ç‡ <70%

### æ•…éšœæ¼”ç»ƒ
- [ ] æ•°æ®åº“ä¸»ä»åˆ‡æ¢
- [ ] Redisæ•…éšœåˆ‡æ¢
- [ ] åº”ç”¨é‡å¯æµ‹è¯•
- [ ] ç½‘ç»œåˆ†åŒºæµ‹è¯•
- [ ] è´Ÿè½½çªå¢æµ‹è¯•

---

## ğŸš¨ ç´§æ€¥å“åº”æµç¨‹

### 1. æœåŠ¡ä¸å¯ç”¨
```bash
# 1. æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:3001/health

# 2. æŸ¥çœ‹æ—¥å¿—
tail -f backend/log/error.log

# 3. é‡å¯æœåŠ¡
pm2 restart backend

# 4. éªŒè¯æ¢å¤
curl http://localhost:3001/api/agents
```

### 2. æ•°æ®åº“è¿æ¥å¤±è´¥
```bash
# 1. æ£€æŸ¥æ•°æ®åº“çŠ¶æ€
psql -h localhost -U llmchat_user -d llmchat -c "SELECT 1"

# 2. æ£€æŸ¥è¿æ¥æ± 
curl http://localhost:3001/metrics | grep db_

# 3. é‡å¯æ•°æ®åº“è¿æ¥æ±  (ä»£ç å±‚é¢)
# éœ€è¦åº”ç”¨é‡å¯
```

### 3. Redisæ•…éšœ
```bash
# 1. æ£€æŸ¥RedisçŠ¶æ€
redis-cli -h localhost -p 6379 PING

# 2. éªŒè¯é™çº§ç”Ÿæ•ˆ
# åº”ç”¨åº”è‡ªåŠ¨åˆ‡æ¢åˆ°å†…å­˜ç¼“å­˜

# 3. é‡å¯Redis (å½±å“æœ€å°åŒ–)
# åº”ç”¨ä¼šè‡ªåŠ¨é‡è¿
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-10-03  
**æœ€åæ›´æ–°**: 2025-10-03  
**è´£ä»»äºº**: å¼€å‘å›¢é˜Ÿ

