name: ğŸ›¡ï¸ Enterprise CI/CD Pipeline - Quality Assurance System

on:
  push:
    branches: [main, develop, release/*]
  pull_request:
    branches: [main, develop]
    types: [opened, synchronize, reopened]
  release:
    types: [published]
  schedule:
    # æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œå…¨é¢æ‰«æ
    - cron: '0 2 * * *'
    # æ¯å‘¨æ—¥æ™šä¸Š8ç‚¹è¿è¡Œæ·±åº¦è´¨é‡æ£€æŸ¥
    - cron: '0 20 * * 0'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'development'
        type: choice
        options:
          - development
          - staging
          - production
      security_scan:
        description: 'Run comprehensive security scan'
        required: false
        default: true
        type: boolean
      performance_test:
        description: 'Run performance tests'
        required: false
        default: false
        type: boolean

env:
  NODE_VERSION: '20'
  PNPM_VERSION: '8.15.0'
  CI: true
  TZ: 'Asia/Shanghai'

# å…¨å±€å˜é‡
vars:
  quality_threshold: '80'
  security_threshold: '0'
  performance_threshold: '95'

jobs:
  # ==========================================
  # é˜¶æ®µ1: ç¯å¢ƒå‡†å¤‡å’Œä¾èµ–éªŒè¯
  # ==========================================
  setup-and-validate:
    name: ğŸš€ Environment Setup & Validation
    runs-on: ubuntu-latest
    outputs:
      cache-hit: ${{ steps.cache.outputs.cache-hit }}
      node-version: ${{ steps.setup.outputs.node-version }}
      should-run-security: ${{ steps.decide.outputs.should-run-security }}
      should-run-performance: ${{ steps.decide.outputs.should-run-performance }}

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: ğŸ”§ Setup Node.js ${{ env.NODE_VERSION }}
        id: setup
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ğŸ“¦ Setup pnpm ${{ env.PNPM_VERSION }}
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ğŸ“š Get pnpm store directory
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: ğŸ’¾ Setup pnpm cache
        id: cache
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: ğŸ“¦ Install Dependencies
        run: |
          echo "ğŸ“¦ Installing dependencies with frozen lockfile..."
          pnpm install --frozen-lockfile --prefer-offline

      - name: ğŸ” Validate Environment Configuration
        run: |
          echo "ğŸ” Validating environment configuration..."

          # æ£€æŸ¥Node.jsç‰ˆæœ¬
          NODE_VERSION_CHECK=$(node -v | cut -d'v' -f2)
          REQUIRED_VERSION="20.0.0"
          if [ "$(printf '%s\n' "$REQUIRED_VERSION" "$NODE_VERSION_CHECK" | sort -V | head -n1)" != "$REQUIRED_VERSION" ]; then
            echo "âŒ Node.js version $NODE_VERSION_CHECK is below required $REQUIRED_VERSION"
            exit 1
          fi
          echo "âœ… Node.js version check passed: $NODE_VERSION_CHECK"

          # æ£€æŸ¥pnpmç‰ˆæœ¬
          PNPM_VERSION_CHECK=$(pnpm -v)
          echo "âœ… pnpm version: $PNPM_VERSION_CHECK"

          # éªŒè¯å·¥ä½œåŒºé…ç½®
          if [ ! -f "pnpm-workspace.yaml" ] && [ ! -f "pnpm-workspace.yml" ]; then
            echo "âš ï¸ No pnpm workspace configuration found"
          else
            echo "âœ… pnpm workspace configuration found"
          fi

          # éªŒè¯package.jsonç»“æ„
          if ! jq empty package.json 2>/dev/null; then
            echo "âŒ Invalid package.json format"
            exit 1
          fi
          echo "âœ… package.json format is valid"

      - name: ğŸ¯ Decide Additional Scans
        id: decide
        run: |
          # å†³å®šæ˜¯å¦è¿è¡Œå®‰å…¨æ‰«æ
          if [[ "${{ github.event_name }}" == "schedule" ]] || [[ "${{ github.event.inputs.security_scan }}" == "true" ]] || [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "should-run-security=true" >> $GITHUB_OUTPUT
          else
            echo "should-run-security=false" >> $GITHUB_OUTPUT
          fi

          # å†³å®šæ˜¯å¦è¿è¡Œæ€§èƒ½æµ‹è¯•
          if [[ "${{ github.event.inputs.performance_test }}" == "true" ]] || [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "should-run-performance=true" >> $GITHUB_OUTPUT
          else
            echo "should-run-performance=false" >> $GITHUB_OUTPUT
          fi

  # ==========================================
  # é˜¶æ®µ2: ä»£ç è´¨é‡æ£€æŸ¥
  # ==========================================
  code-quality:
    name: ğŸ” Code Quality Analysis
    runs-on: ubuntu-latest
    needs: setup-and-validate

    strategy:
      matrix:
        check-type: [typescript, eslint, prettier, complexity]
        include:
          - check-type: typescript
            command: pnpm run type-check
            name: "TypeScript Type Check"
            icon: "ğŸ“"
          - check-type: eslint
            command: pnpm run lint
            name: "ESLint Quality Check"
            icon: "ğŸ”"
          - check-type: prettier
            command: pnpm run prettier:check || pnpm prettier --check .
            name: "Prettier Format Check"
            icon: "ğŸ¨"
          - check-type: complexity
            command: pnpm run complexity:check || echo "Complexity check not configured"
            name: "Code Complexity Analysis"
            icon: "ğŸ“Š"

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ needs.setup-and-validate.outputs.node-version }}
          cache: 'pnpm'

      - name: ğŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ğŸ’¾ Restore pnpm cache
        uses: actions/cache@v4
        with:
          path: ~/.pnpm-store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: ğŸ“¦ Install Dependencies
        run: pnpm install --frozen-lockfile

      - name: ${{ matrix.icon }} ${{ matrix.name }}
        id: quality-check
        run: |
          echo "::group::${{ matrix.name }}"
          echo "Running: ${{ matrix.command }}"

          # åˆ›å»ºè´¨é‡æŠ¥å‘Šç›®å½•
          mkdir -p quality-reports

          # è¿è¡Œæ£€æŸ¥å¹¶æ•è·ç»“æœ
          if ${{ matrix.command }}; then
            echo "${{ matrix.check-type }}_status=passed" >> $GITHUB_OUTPUT
            echo "âœ… ${{ matrix.name }} passed"
          else
            echo "${{ matrix.check-type }}_status=failed" >> $GITHUB_OUTPUT
            echo "âŒ ${{ matrix.name }} failed"
            echo "::endgroup::"
            exit 1
          fi
          echo "::endgroup::"

      - name: ğŸ“Š Upload Quality Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quality-results-${{ matrix.check-type }}
          path: |
            quality-reports/
            eslint-report.json
            tsconfig.json
          retention-days: 30

  # ==========================================
  # é˜¶æ®µ3: æµ‹è¯•å¥—ä»¶
  # ==========================================
  test-suite:
    name: ğŸ§ª Test Suite
    runs-on: ubuntu-latest
    needs: setup-and-validate

    strategy:
      matrix:
        test-type: [unit, integration, e2e]
        include:
          - test-type: unit
            name: "Unit Tests"
            command: pnpm test
            coverage: true
            icon: "ğŸ”¬"
          - test-type: integration
            name: "Integration Tests"
            command: pnpm run test:integration || echo "Integration tests not configured"
            coverage: false
            icon: "ğŸ”—"
          - test-type: e2e
            name: "E2E Tests"
            command: pnpm run test:e2e
            coverage: false
            icon: "ğŸŒ"
            setup: true

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ needs.setup-and-validate.outputs.node-version }}
          cache: 'pnpm'

      - name: ğŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ğŸ’¾ Restore pnpm cache
        uses: actions/cache@v4
        with:
          path: ~/.pnpm-store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: ğŸ“¦ Install Dependencies
        run: pnpm install --frozen-lockfile

      - name: ğŸŒ Setup E2E Dependencies
        if: matrix.setup
        run: |
          pnpm exec playwright install --with-deps
          pnpm exec playwright install-deps

      - name: ${{ matrix.icon }} ${{ matrix.name }}
        id: test-run
        run: |
          echo "::group::${{ matrix.name }}"

          # åˆ›å»ºæµ‹è¯•æŠ¥å‘Šç›®å½•
          mkdir -p test-reports
          mkdir -p coverage

          # è¿è¡Œæµ‹è¯•
          if ${{ matrix.command }}; then
            echo "${{ matrix.test-type }}_status=passed" >> $GITHUB_OUTPUT
            echo "âœ… ${{ matrix.name }} passed"
          else
            echo "${{ matrix.test-type }}_status=failed" >> $GITHUB_OUTPUT
            echo "âŒ ${{ matrix.name }} failed"
            echo "::endgroup::"
            exit 1
          fi
          echo "::endgroup::"

      - name: ğŸ“Š Process Coverage Reports
        if: matrix.coverage && steps.test-run.outputs.${{ matrix.test-type }}_status == 'passed'
        run: |
          echo "ğŸ“Š Processing coverage reports..."

          # åˆå¹¶è¦†ç›–ç‡æŠ¥å‘Š
          if [ -f "coverage/lcov.info" ]; then
            echo "âœ… Coverage report found"
            # ç”Ÿæˆè¦†ç›–ç‡æ‘˜è¦
            npx nyc report --reporter=text-summary > test-reports/coverage-summary.txt || true
            npx nyc report --reporter=json > test-reports/coverage-summary.json || true
          else
            echo "âš ï¸ No coverage report found"
          fi

      - name: ğŸ“¤ Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.test-type }}
          path: |
            test-reports/
            coverage/
            playwright-report/
            test-results/
          retention-days: 30

  # ==========================================
  # é˜¶æ®µ4: å®‰å…¨æ‰«æ
  # ==========================================
  security-scan:
    name: ğŸ”’ Security Vulnerability Scan
    runs-on: ubuntu-latest
    needs: setup-and-validate
    if: needs.setup-and-validate.outputs.should-run-security == 'true'

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ needs.setup-and-validate.outputs.node-version }}
          cache: 'pnpm'

      - name: ğŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ğŸ“¦ Install Dependencies
        run: pnpm install --frozen-lockfile

      - name: ğŸ” Dependency Security Audit
        id: audit
        run: |
          echo "::group::Dependency Security Audit"

          # åˆ›å»ºå®‰å…¨æŠ¥å‘Šç›®å½•
          mkdir -p security-reports

          # è¿è¡Œå®‰å…¨å®¡è®¡
          if pnpm audit --audit-level moderate --json > security-reports/audit-report.json 2>/dev/null; then
            echo "audit_status=passed" >> $GITHUB_OUTPUT
            echo "vulnerabilities=0" >> $GITHUB_OUTPUT
            echo "âœ… No security vulnerabilities found"
          else
            # æå–æ¼æ´æ•°é‡
            VULNS=$(cat security-reports/audit-report.json | jq '.vulnerabilities | length' 2>/dev/null || echo "0")
            echo "vulnerabilities=$VULNS" >> $GITHUB_OUTPUT

            if [ "$VULNS" -eq 0 ]; then
              echo "audit_status=passed" >> $GITHUB_OUTPUT
              echo "âœ… No security vulnerabilities found"
            elif [ "$VULNS" -le 5 ]; then
              echo "audit_status=warning" >> $GITHUB_OUTPUT
              echo "âš ï¸ Found $VULNS low/moderate vulnerabilities"
            else
              echo "audit_status=failed" >> $GITHUB_OUTPUT
              echo "ğŸš¨ Found $VULNS security vulnerabilities"
              echo "::endgroup::"
              exit 1
            fi
          fi
          echo "::endgroup::"

      - name: ğŸ” Code Security Analysis
        id: code-security
        run: |
          echo "::group::Code Security Analysis"

          # è¿è¡Œä»£ç å®‰å…¨æ£€æŸ¥
          if command -v semgrep &> /dev/null; then
            echo "Running Semgrep security scan..."
            semgrep --config=auto --json --output=security-reports/semgrep-report.json . || true

            # åˆ†æç»“æœ
            if [ -f "security-reports/semgrep-report.json" ]; then
              SEMGREP_ISSUES=$(cat security-reports/semgrep-report.json | jq '.results | length' 2>/dev/null || echo "0")
              echo "semgrep_issues=$SEMGREP_ISSUES" >> $GITHUB_OUTPUT

              if [ "$SEMGREP_ISSUES" -eq 0 ]; then
                echo "code_security_status=passed" >> $GITHUB_OUTPUT
                echo "âœ… No code security issues found"
              elif [ "$SEMGREP_ISSUES" -le 10 ]; then
                echo "code_security_status=warning" >> $GITHUB_OUTPUT
                echo "âš ï¸ Found $SEMGREP_ISSUES code security issues"
              else
                echo "code_security_status=failed" >> $GITHUB_OUTPUT
                echo "ğŸš¨ Found $SEMGREP_ISSUES code security issues"
              fi
            else
              echo "code_security_status=skipped" >> $GITHUB_OUTPUT
              echo "â­ï¸ Semgrep not available, skipping code security scan"
            fi
          else
            echo "code_security_status=skipped" >> $GITHUB_OUTPUT
            echo "â­ï¸ Semgrep not installed, skipping code security scan"
          fi
          echo "::endgroup::"

      - name: ğŸ”’ Secret Scan
        id: secret-scan
        run: |
          echo "::group::Secret Scan"

          # æ‰«ææ•æ„Ÿä¿¡æ¯
          if command -v gitleaks &> /dev/null; then
            echo "Running Gitleaks secret scan..."
            gitleaks detect --source=. --report-path=security-reports/gitleaks-report.json --report-format=json || true

            if [ -f "security-reports/gitleaks-report.json" ]; then
              SECRETS_FOUND=$(cat security-reports/gitleaks-report.json | jq '. | length' 2>/dev/null || echo "0")
              echo "secrets_found=$SECRETS_FOUND" >> $GITHUB_OUTPUT

              if [ "$SECRETS_FOUND" -eq 0 ]; then
                echo "secret_status=passed" >> $GITHUB_OUTPUT
                echo "âœ… No secrets found in code"
              else
                echo "secret_status=failed" >> $GITHUB_OUTPUT
                echo "ğŸš¨ Found $SECRETS_FOUND potential secrets"
                exit 1
              fi
            else
              echo "secret_status=skipped" >> $GITHUB_OUTPUT
              echo "â­ï¸ Gitleaks report not generated"
            fi
          else
            echo "secret_status=skipped" >> $GITHUB_OUTPUT
            echo "â­ï¸ Gitleaks not installed, skipping secret scan"
          fi
          echo "::endgroup::"

      - name: ğŸ“¤ Upload Security Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            security-reports/
          retention-days: 90

  # ==========================================
  # é˜¶æ®µ5: æ„å»ºéªŒè¯
  # ==========================================
  build-validation:
    name: ğŸ—ï¸ Build Validation
    runs-on: ubuntu-latest
    needs: [setup-and-validate, code-quality]

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ needs.setup-and-validate.outputs.node-version }}
          cache: 'pnpm'

      - name: ğŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ğŸ’¾ Restore pnpm cache
        uses: actions/cache@v4
        with:
          path: ~/.pnpm-store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: ğŸ“¦ Install Dependencies
        run: pnpm install --frozen-lockfile

      - name: ğŸ—ï¸ Build Application
        id: build
        run: |
          echo "::group::Building Application"

          # åˆ›å»ºæ„å»ºæŠ¥å‘Šç›®å½•
          mkdir -p build-reports

          # è®°å½•æ„å»ºå¼€å§‹æ—¶é—´
          BUILD_START=$(date +%s)

          # è¿è¡Œæ„å»º
          if pnpm run build; then
            BUILD_END=$(date +%s)
            BUILD_DURATION=$((BUILD_END - BUILD_START))

            echo "build_status=success" >> $GITHUB_OUTPUT
            echo "build_duration=$BUILD_DURATION" >> $GITHUB_OUTPUT
            echo "âœ… Build successful (${BUILD_DURATION}s)"

            # åˆ†ææ„å»ºäº§ç‰©
            if [ -d "backend/dist" ]; then
              BACKEND_SIZE=$(du -sh backend/dist | cut -f1)
              echo "backend_size=$BACKEND_SIZE" >> $GITHUB_OUTPUT
            fi

            if [ -d "frontend/dist" ]; then
              FRONTEND_SIZE=$(du -sh frontend/dist | cut -f1)
              echo "frontend_size=$FRONTEND_SIZE" >> $GITHUB_OUTPUT
            fi

          else
            echo "build_status=failed" >> $GITHUB_OUTPUT
            echo "âŒ Build failed"
            echo "::endgroup::"
            exit 1
          fi
          echo "::endgroup::"

      - name: ğŸ“Š Analyze Build Artifacts
        if: steps.build.outputs.build_status == 'success'
        run: |
          echo "ğŸ“Š Analyzing build artifacts..."

          # ç”Ÿæˆæ„å»ºåˆ†ææŠ¥å‘Š
          cat > build-reports/build-analysis.md << EOF
          # Build Analysis Report

          ## Build Information
          - **Build Status**: ${{ steps.build.outputs.build_status }}
          - **Build Duration**: ${{ steps.build.outputs.build_duration }}s
          - **Backend Size**: ${{ steps.build.outputs.backend_size || 'N/A' }}
          - **Frontend Size**: ${{ steps.build.outputs.frontend_size || 'N/A' }}

          ## Build Artifacts
          EOF

          # åˆ—å‡ºæ„å»ºäº§ç‰©
          if [ -d "backend/dist" ]; then
            echo "- Backend dist/" >> build-reports/build-analysis.md
            find backend/dist -type f | head -10 >> build-reports/build-analysis.md
          fi

          if [ -d "frontend/dist" ]; then
            echo "- Frontend dist/" >> build-reports/build-analysis.md
            find frontend/dist -type f | head -10 >> build-reports/build-analysis.md
          fi

      - name: ğŸ“¤ Upload Build Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts
          path: |
            backend/dist/
            frontend/dist/
            build-reports/
          retention-days: 7

  # ==========================================
  # é˜¶æ®µ6: è´¨é‡é—¨ç¦è¯„ä¼°
  # ==========================================
  quality-gates:
    name: ğŸ›¡ï¸ Quality Gates Assessment
    runs-on: ubuntu-latest
    needs: [code-quality, test-suite, security-scan, build-validation]
    if: always()

    outputs:
      overall-status: ${{ steps.assessment.outputs.overall-status }}
      quality-score: ${{ steps.assessment.outputs.quality-score }}
      deployment-ready: ${{ steps.assessment.outputs.deployment-ready }}

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ“Š Download All Reports
        uses: actions/download-artifact@v4
        with:
          pattern: "*-results-*"
          merge-multiple: true
          path: all-reports/

      - name: ğŸ›¡ï¸ Quality Gates Assessment
        id: assessment
        run: |
          echo "::group::Quality Gates Assessment"

          # åˆå§‹åŒ–åˆ†æ•°
          QUALITY_SCORE=100
          OVERALL_STATUS="passed"
          DEPLOYMENT_READY="true"

          # è¯„ä¼°ä»£ç è´¨é‡
          echo "ğŸ” Evaluating code quality..."
          CODE_QUALITY_STATUS="${{ needs.code-quality.result }}"
          if [ "$CODE_QUALITY_STATUS" != "success" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE - 30))
            OVERALL_STATUS="warning"
            echo "âš ï¸ Code quality issues detected"
          else
            echo "âœ… Code quality checks passed"
          fi

          # è¯„ä¼°æµ‹è¯•ç»“æœ
          echo "ğŸ§ª Evaluating test results..."
          TEST_STATUS="${{ needs.test-suite.result }}"
          if [ "$TEST_STATUS" != "success" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE - 25))
            OVERALL_STATUS="failed"
            DEPLOYMENT_READY="false"
            echo "âŒ Test failures detected"
          else
            echo "âœ… All tests passed"
          fi

          # è¯„ä¼°å®‰å…¨æ‰«æ
          echo "ğŸ”’ Evaluating security scan..."
          SECURITY_STATUS="${{ needs.security-scan.result }}"
          if [ "$SECURITY_STATUS" == "failure" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE - 20))
            OVERALL_STATUS="failed"
            DEPLOYMENT_READY="false"
            echo "ğŸš¨ Security vulnerabilities detected"
          elif [ "$SECURITY_STATUS" == "success" ]; then
            echo "âœ… Security scan passed"
          else
            echo "â­ï¸ Security scan skipped"
          fi

          # è¯„ä¼°æ„å»ºç»“æœ
          echo "ğŸ—ï¸ Evaluating build validation..."
          BUILD_STATUS="${{ needs.build-validation.result }}"
          if [ "$BUILD_STATUS" != "success" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE - 25))
            OVERALL_STATUS="failed"
            DEPLOYMENT_READY="false"
            echo "âŒ Build validation failed"
          else
            echo "âœ… Build validation passed"
          fi

          # ç¡®ä¿åˆ†æ•°ä¸ä½äº0
          if [ $QUALITY_SCORE -lt 0 ]; then
            QUALITY_SCORE=0
          fi

          # è®¾ç½®è¾“å‡º
          echo "overall-status=$OVERALL_STATUS" >> $GITHUB_OUTPUT
          echo "quality-score=$QUALITY_SCORE" >> $GITHUB_OUTPUT
          echo "deployment-ready=$DEPLOYMENT_READY" >> $GITHUB_OUTPUT

          echo "ğŸ“Š Quality Score: $QUALITY_SCORE/100"
          echo "ğŸš¦ Overall Status: $OVERALL_STATUS"
          echo "ğŸš€ Deployment Ready: $DEPLOYMENT_READY"
          echo "::endgroup::"

      - name: ğŸ“‹ Generate Quality Report
        if: always()
        run: |
          echo "ğŸ“‹ Generating comprehensive quality report..."

          mkdir -p final-reports

          cat > final-reports/quality-report.md << EOF
          # LLMChat CI/CD Quality Report

          ## ğŸ“Š Executive Summary
          - **Quality Score**: ${{ steps.assessment.outputs.quality-score }}/100
          - **Overall Status**: ${{ steps.assessment.outputs.overall-status }}
          - **Deployment Ready**: ${{ steps.assessment.outputs.deployment-ready }}
          - **Build Number**: ${{ github.run_number }}
          - **Commit SHA**: ${{ github.sha }}
          - **Branch**: ${{ github.ref_name }}
          - **Triggered By**: ${{ github.event_name }}

          ## ğŸ›¡ï¸ Quality Gates Results

          ### Code Quality
          - **Status**: ${{ needs.code-quality.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }}
          - **Impact**: Critical for code maintainability

          ### Test Suite
          - **Status**: ${{ needs.test-suite.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }}
          - **Impact**: Critical for functionality assurance

          ### Security Scan
          - **Status**: ${{ needs.security-scan.result == 'success' && 'âœ… Passed' || needs.security-scan.result == 'failure' && 'âŒ Failed' || 'â­ï¸ Skipped' }}
          - **Impact**: Critical for production security

          ### Build Validation
          - **Status**: ${{ needs.build-validation.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }}
          - **Impact**: Critical for deployment readiness

          ## ğŸ¯ Recommendations

          ${{ steps.assessment.outputs.quality-score >= 90 && 'ğŸŒŸ Excellent quality! Ready for production deployment.' || '' }}
          ${{ steps.assessment.outputs.quality-score >= 80 && steps.assessment.outputs.quality-score < 90 && 'âœ… Good quality. Consider minor improvements before production.' || '' }}
          ${{ steps.assessment.outputs.quality-score >= 70 && steps.assessment.outputs.quality-score < 80 && 'âš ï¸ Acceptable quality. Address issues before production deployment.' || '' }}
          ${{ steps.assessment.outputs.quality-score < 70 && 'âŒ Poor quality. Significant improvements required before deployment.' || '' }}

          ---
          *Report generated on $(date -u)*
          *Powered by LLMChat CI/CD Pipeline*
          EOF

      - name: ğŸ“¤ Upload Final Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: final-quality-report
          path: final-reports/
          retention-days: 90

      - name: ğŸš« Quality Gates Enforcement
        if: steps.assessment.outputs.overall-status == 'failed'
        run: |
          echo "âŒ Quality gates failed - blocking deployment"
          echo "ğŸ“Š Quality Score: ${{ steps.assessment.outputs.quality-score }}/100"
          echo "ğŸš¦ Overall Status: ${{ steps.assessment.outputs.overall-status }}"
          exit 1

      - name: ğŸ’¬ PR Quality Comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            try {
              const reportPath = 'final-reports/quality-report.md';
              if (fs.existsSync(reportPath)) {
                const report = fs.readFileSync(reportPath, 'utf8');

                await github.rest.issues.createComment({
                  issue_number: context.issue.number,
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  body: `## ğŸ›¡ï¸ CI/CD Quality Report\n\n${report}`
                });

                console.log('âœ… Quality report commented to PR');
              }
            } catch (error) {
              console.log('âŒ Error commenting PR:', error.message);
            }

  # ==========================================
  # é˜¶æ®µ7: éƒ¨ç½²æµæ°´çº¿
  # ==========================================
  deploy:
    name: ğŸš€ Deploy to Environment
    runs-on: ubuntu-latest
    needs: [setup-and-validate, quality-gates]
    if: needs.quality-gates.outputs.deployment-ready == 'true' && github.event_name != 'pull_request'
    environment:
      name: ${{ github.event.inputs.environment || 'development' }}
      url: ${{ steps.deploy.outputs.url }}

    strategy:
      matrix:
        environment: [development, staging, production]
        include:
          - environment: development
            branch: develop
            required_score: 70
          - environment: staging
            branch: main
            required_score: 80
          - environment: production
            branch: main
            required_score: 90
        exclude:
          - environment: production
            branch: develop
          - environment: staging
            branch: develop
          - environment: development
            branch: main

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ needs.setup-and-validate.outputs.node-version }}
          cache: 'pnpm'

      - name: ğŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ğŸ“¦ Install Dependencies
        run: pnpm install --frozen-lockfile

      - name: ğŸ“¥ Download Build Artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts
          path: ./

      - name: ğŸš€ Deploy to ${{ matrix.environment }}
        id: deploy
        run: |
          echo "::group::Deploying to ${{ matrix.environment }}"

          # éªŒè¯éƒ¨ç½²æ¡ä»¶
          QUALITY_SCORE=${{ needs.quality-gates.outputs.quality-score }}
          REQUIRED_SCORE=${{ matrix.required_score }}

          if [ "$QUALITY_SCORE" -lt "$REQUIRED_SCORE" ]; then
            echo "âŒ Quality score $QUALITY_SCORE is below required $REQUIRED_SCORE for ${{ matrix.environment }}"
            exit 1
          fi

          echo "âœ… Quality score $QUALITY_SCORE meets requirements for ${{ matrix.environment }}"

          # éƒ¨ç½²é€»è¾‘ï¼ˆç¤ºä¾‹ï¼‰
          echo "ğŸš€ Deploying to ${{ matrix.environment }}..."

          # è¿™é‡Œæ·»åŠ å®é™…çš„éƒ¨ç½²é€»è¾‘
          # ä¾‹å¦‚ï¼šDockeréƒ¨ç½²ã€K8séƒ¨ç½²ã€äº‘æœåŠ¡éƒ¨ç½²ç­‰

          # è®¾ç½®éƒ¨ç½²URL
          if [ "${{ matrix.environment }}" == "development" ]; then
            echo "url=https://dev.llmchat.example.com" >> $GITHUB_OUTPUT
          elif [ "${{ matrix.environment }}" == "staging" ]; then
            echo "url=https://staging.llmchat.example.com" >> $GITHUB_OUTPUT
          elif [ "${{ matrix.environment }}" == "production" ]; then
            echo "url=https://llmchat.example.com" >> $GITHUB_OUTPUT
          fi

          echo "âœ… Deployment to ${{ matrix.environment }} completed"
          echo "::endgroup::"

      - name: ğŸ” Post-Deployment Health Check
        run: |
          echo "::group::Post-Deployment Health Check"

          # ç­‰å¾…éƒ¨ç½²å¯åŠ¨
          sleep 30

          # å¥åº·æ£€æŸ¥
          DEPLOY_URL="${{ steps.deploy.outputs.url }}"
          if [ -n "$DEPLOY_URL" ]; then
            echo "ğŸ” Checking health at $DEPLOY_URL"

            # æ£€æŸ¥APIå¥åº·çŠ¶æ€
            if curl -f "$DEPLOY_URL/api/health" --max-time 30 --retry 3 --retry-delay 10; then
              echo "âœ… API health check passed"
            else
              echo "âŒ API health check failed"
              exit 1
            fi

            # æ£€æŸ¥å‰ç«¯å¥åº·çŠ¶æ€
            if curl -f "$DEPLOY_URL" --max-time 30 --retry 3 --retry-delay 10; then
              echo "âœ… Frontend health check passed"
            else
              echo "âŒ Frontend health check failed"
              exit 1
            fi
          else
            echo "âš ï¸ No deployment URL provided, skipping health checks"
          fi

          echo "::endgroup::"

      - name: ğŸ“Š Deployment Metrics
        run: |
          echo "::group::Deployment Metrics"

          echo "ğŸ“Š Deployment metrics for ${{ matrix.environment }}:"
          echo "- Environment: ${{ matrix.environment }}"
          echo "- Quality Score: ${{ needs.quality-gates.outputs.quality-score }}/100"
          echo "- Required Score: ${{ matrix.required_score }}"
          echo "- Deployment URL: ${{ steps.deploy.outputs.url }}"
          echo "- Deployment Time: $(date -u)"
          echo "- Build Number: ${{ github.run_number }}"
          echo "- Commit SHA: ${{ github.sha }}"

          echo "::endgroup::"

      - name: ğŸ“¢ Deployment Notification
        if: always()
        run: |
          echo "::group::Deployment Notification"

          if [ "${{ job.status }}" == "success" ]; then
            echo "âœ… Deployment to ${{ matrix.environment }} completed successfully!"
            echo "ğŸ”— URL: ${{ steps.deploy.outputs.url }}"
          else
            echo "âŒ Deployment to ${{ matrix.environment }} failed"
            echo "ğŸ” Please check the deployment logs"
          fi

          echo "::endgroup::"

  # ==========================================
  # é˜¶æ®µ8: æ€§èƒ½æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
  # ==========================================
  performance-test:
    name: ğŸ“Š Performance Testing
    runs-on: ubuntu-latest
    needs: [setup-and-validate, deploy]
    if: needs.setup-and-validate.outputs.should-run-performance == 'true' && needs.deploy.result == 'success'

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ğŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ needs.setup-and-validate.outputs.node-version }}

      - name: ğŸ“¦ Install Performance Testing Tools
        run: |
          npm install -g artillery
          npm install -g lighthouse

      - name: ğŸš€ API Performance Test
        run: |
          echo "::group::API Performance Testing"

          # åˆ›å»ºæ€§èƒ½æµ‹è¯•é…ç½®
          cat > artillery-config.yml << EOF
          config:
            target: '\${{ steps.deploy.outputs.url }}/api'
            phases:
              - duration: 60
                arrivalRate: 10
              - duration: 120
                arrivalRate: 20
              - duration: 60
                arrivalRate: 5
            processor: "./test-processor.js"

          scenarios:
            - name: "API Load Test"
              weight: 70
              requests:
                - get:
                    url: "/health"
                - get:
                    url: "/agents"
            - name: "API Stress Test"
              weight: 30
              requests:
                - post:
                    url: "/chat/completions"
                    json:
                      model: "test"
                      messages: [{"role": "user", "content": "Hello"}]
          EOF

          # è¿è¡ŒAPIæ€§èƒ½æµ‹è¯•
          artillery run artillery-config.yml --output performance-results.json

          echo "::endgroup::"

      - name: ğŸŒ Frontend Performance Test
        run: |
          echo "::group::Frontend Performance Testing"

          # åˆ›å»ºLighthouseé…ç½®
          mkdir -p lighthouse-reports

          # è¿è¡ŒLighthouseæµ‹è¯•
          lighthouse "${{ steps.deploy.outputs.url }}" \
            --output=json --output-path=./lighthouse-reports/report.json \
            --chrome-flags="--headless --no-sandbox" \
            --quiet

          echo "::endgroup::"

      - name: ğŸ“Š Performance Analysis
        run: |
          echo "::group::Performance Analysis"

          # åˆ†æAPIæ€§èƒ½ç»“æœ
          if [ -f "performance-results.json" ]; then
            echo "ğŸ“Š API Performance Results:"
            jq '.aggregate | {rps: .http.responses, latency: .latency, errors: .errors}' performance-results.json
          fi

          # åˆ†æå‰ç«¯æ€§èƒ½ç»“æœ
          if [ -f "lighthouse-reports/report.json" ]; then
            echo "ğŸŒ Frontend Performance Results:"
            jq '.lhrCategories | {performance: .performance.score, accessibility: .accessibility.score, "best-practices": .["best-practices"].score, seo: .seo.score}' lighthouse-reports/report.json
          fi

          echo "::endgroup::"

      - name: ğŸ“¤ Upload Performance Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-reports
          path: |
            performance-results.json
            lighthouse-reports/
          retention-days: 30

  # ==========================================
  # é˜¶æ®µ9: é€šçŸ¥å’ŒæŠ¥å‘Š
  # ==========================================
  notify-and-report:
    name: ğŸ“¢ Notify and Report
    runs-on: ubuntu-latest
    needs: [quality-gates, deploy, performance-test]
    if: always()

    steps:
      - name: ğŸ“Š Download Final Report
        if: always()
        uses: actions/download-artifact@v4
        with:
          name: final-quality-report
          path: final-report/

      - name: ğŸ“¢ Pipeline Summary
        if: always()
        run: |
          echo "# ğŸš€ LLMChat CI/CD Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ğŸ“Š Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Quality Gates**: ${{ needs.quality-gates.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Quality Score**: ${{ needs.quality-gates.outputs.quality-score }}/100" >> $GITHUB_STEP_SUMMARY
          echo "- **Deployment**: ${{ needs.deploy.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Performance Tests**: ${{ needs.performance-test.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.quality-gates.result }}" == "success" ] && [ "${{ needs.deploy.result }}" == "success" ]; then
            echo "## ğŸ‰ Overall Status: SUCCESS" >> $GITHUB_STEP_SUMMARY
            echo "âœ… Pipeline completed successfully!" >> $GITHUB_STEP_SUMMARY
          else
            echo "## âŒ Overall Status: FAILED" >> $GITHUB_STEP_SUMMARY
            echo "âŒ Pipeline failed, please review the logs." >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ğŸ“‹ Detailed Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Build**: ${{ needs.build-validation.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Code Quality**: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Tests**: ${{ needs.test-suite.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Security**: ${{ needs.security-scan.result }}" >> $GITHUB_STEP_SUMMARY

      - name: ğŸ“§ Send Notification (on failure)
        if: needs.quality-gates.result == 'failure' || needs.deploy.result == 'failure'
        run: |
          echo "ğŸ“§ Sending failure notification..."
          # è¿™é‡Œå¯ä»¥æ·»åŠ é‚®ä»¶ã€Slackã€Teamsç­‰é€šçŸ¥é€»è¾‘
          echo "Pipeline failed - notification sent"

      - name: ğŸ‰ Send Notification (on success)
        if: needs.quality-gates.result == 'success' && needs.deploy.result == 'success'
        run: |
          echo "ğŸ‰ Sending success notification..."
          # è¿™é‡Œå¯ä»¥æ·»åŠ æˆåŠŸé€šçŸ¥é€»è¾‘
          echo "Pipeline completed successfully - notification sent"