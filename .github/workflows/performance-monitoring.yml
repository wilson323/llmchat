name: ðŸ“Š Performance Monitoring & Auto-Optimization

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  schedule:
    # æ¯å°æ—¶è¿è¡Œæ€§èƒ½ç›‘æŽ§
    - cron: '0 * * * *'
    # æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œæ·±åº¦æ€§èƒ½åˆ†æž
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      monitoring_type:
        description: 'Type of monitoring'
        required: true
        default: 'comprehensive'
        type: choice
        options:
          - basic
          - comprehensive
          - deep-analysis
          - regression-test
      environment:
        description: 'Target environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - development
          - staging
          - production
      generate_optimization:
        description: 'Generate optimization recommendations'
        required: false
        default: true
        type: boolean
      alert_threshold:
        description: 'Performance alert threshold (ms)'
        required: false
        default: '2000'
        type: string

env:
  NODE_VERSION: '20'
  PNPM_VERSION: '8.15.0'

jobs:
  # ==========================================
  # æ™ºèƒ½åŒ–æ€§èƒ½ç›‘æŽ§è®¾ç½®
  # ==========================================
  performance-monitoring-setup:
    name: ðŸ”§ Performance Monitoring Setup
    runs-on: ubuntu-latest
    outputs:
      monitoring-scope: ${{ steps.setup.outputs.monitoring-scope }}
      test-environment: ${{ steps.setup.outputs.test-environment }}
      monitoring-targets: ${{ steps.setup.outputs.monitoring-targets }}
      optimization-enabled: ${{ steps.setup.outputs.optimization-enabled }}

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Performance Monitoring Configuration
        id: setup
        run: |
          echo "::group::Performance Monitoring Configuration"

          # ç¡®å®šç›‘æŽ§èŒƒå›´
          MONITORING_TYPE="${{ github.event.inputs.monitoring_type || 'comprehensive' }}"
          ENVIRONMENT="${{ github.event.inputs.environment || 'staging' }}"

          case $MONITORING_TYPE in
            "basic")
              MONITORING_SCOPE="basic"
              MONITORING_TARGETS='["frontend", "backend"]'
              ;;
            "comprehensive")
              MONITORING_SCOPE="comprehensive"
              MONITORING_TARGETS='["frontend", "backend", "database", "network"]'
              ;;
            "deep-analysis")
              MONITORING_SCOPE="deep"
              MONITORING_TARGETS='["frontend", "backend", "database", "network", "memory", "cpu"]'
              ;;
            "regression-test")
              MONITORING_SCOPE="regression"
              MONITORING_TARGETS='["frontend", "backend"]'
              ;;
          esac

          # è®¾ç½®è¾“å‡º
          echo "monitoring-scope=$MONITORING_SCOPE" >> $GITHUB_OUTPUT
          echo "test-environment=$ENVIRONMENT" >> $GITHUB_OUTPUT
          echo "monitoring-targets=$MONITORING_TARGETS" >> $GITHUB_OUTPUT
          echo "optimization-enabled=${{ github.event.inputs.generate_optimization || 'true' }}" >> $GITHUB_OUTPUT

          echo "âœ… Performance monitoring configured"
          echo "- Scope: $MONITORING_SCOPE"
          echo "- Environment: $ENVIRONMENT"
          echo "- Targets: $MONITORING_TARGETS"
          echo "- Optimization: ${{ github.event.inputs.generate_optimization || 'true' }}"
          echo "::endgroup::"

  # ==========================================
  # å‰ç«¯æ€§èƒ½ç›‘æŽ§
  # ==========================================
  frontend-performance-monitoring:
    name: ðŸŒ Frontend Performance Monitoring
    runs-on: ubuntu-latest
    needs: performance-monitoring-setup
    if: contains(needs.performance-monitoring-setup.outputs.monitoring-targets, 'frontend')

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ðŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ðŸ“¦ Install Dependencies
        run: pnpm install --frozen-lockfile

      - name: ðŸ—ï¸ Build Frontend
        run: pnpm run frontend:build

      - name: ðŸŒ Lighthouse Performance Audit
        id: lighthouse
        run: |
          echo "::group::Lighthouse Performance Audit"

          # å®‰è£… Lighthouse
          npm install -g @lhci/cli@0.12.x

          # åˆ›å»º Lighthouse é…ç½®
          mkdir -p lighthouse-reports

          # è¿è¡Œ Lighthouse å®¡è®¡
          lhci autorun \
            --config=.lighthouserc.js \
            --upload.target=temporary-public-storage \
            --collect.url=http://localhost:3000 \
            --collect.numberOfRuns=3 || echo "Lighthouse audit completed with warnings"

          # åˆ†æžç»“æžœ
          if [ -f "lighthouse-reports/lhr.json" ]; then
            # æå–å…³é”®æŒ‡æ ‡
            PERFORMANCE_SCORE=$(cat lighthouse-reports/lhr.json | jq -r '.lhrCategories.performance.score * 100' 2>/dev/null || echo "0")
            FCP=$(cat lighthouse-reports/lhr.json | jq -r '.audits["first-contentful-paint"].numericValue' 2>/dev/null || echo "0")
            LCP=$(cat lighthouse-reports/lhr.json | jq -r '.audits["largest-contentful-paint"].numericValue' 2>/dev/null || echo "0")
            TTI=$(cat lighthouse-reports/lhr.json | jq -r '.audits["interactive"].numericValue' 2>/dev/null || echo "0")
            CLS=$(cat lighthouse-reports/lhr.json | jq -r '.audits["cumulative-layout-shift"].numericValue' 2>/dev/null || echo "0")
            FID=$(cat lighthouse-reports/lhr.json | jq -r '.audits["max-potential-fid"].numericValue' 2>/dev/null || echo "0")

            echo "performance-score=$PERFORMANCE_SCORE" >> $GITHUB_OUTPUT
            echo "fcp=$FCP" >> $GITHUB_OUTPUT
            echo "lcp=$LCP" >> $GITHUB_OUTPUT
            echo "tti=$TTI" >> $GITHUB_OUTPUT
            echo "cls=$CLS" >> $GITHUB_OUTPUT
            echo "fid=$FID" >> $GITHUB_OUTPUT

            echo "ðŸ“Š Frontend Performance Metrics:"
            echo "- Performance Score: $PERFORMANCE_SCORE"
            echo "- First Contentful Paint: ${FCP}ms"
            echo "- Largest Contentful Paint: ${LCP}ms"
            echo "- Time to Interactive: ${TTI}ms"
            echo "- Cumulative Layout Shift: $CLS"
            echo "- First Input Delay: ${FID}ms"
          else
            echo "âš ï¸ Lighthouse report not found"
          fi

          echo "::endgroup::"

      - name: ðŸ“Š Bundle Size Analysis
        id: bundle-analysis
        run: |
          echo "::group::Bundle Size Analysis"

          if [ -d "frontend/dist" ]; then
            # åˆ†æžå‰ç«¯æž„å»ºäº§ç‰©å¤§å°
            FRONTEND_SIZE=$(du -sh frontend/dist | cut -f1)
            JS_SIZE=$(du -sh frontend/dist/**/*.js 2>/dev/null | awk '{sum+=$1} END {print sum}' || echo "0")
            CSS_SIZE=$(du -sh frontend/dist/**/*.css 2>/dev/null | awk '{sum+=$1} END {print sum}' || echo "0")

            # åˆ†æžä¸»è¦æ–‡ä»¶
            MAIN_JS_SIZE=$(du -sh frontend/dist/**/*.js 2>/dev/null | sort -hr | head -1 | cut -f1 || echo "0")
            MAIN_CSS_SIZE=$(du -sh frontend/dist/**/*.css 2>/dev/null | sort -hr | head -1 | cut -f1 || echo "0")

            echo "frontend-size=$FRONTEND_SIZE" >> $GITHUB_OUTPUT
            echo "js-size=$JS_SIZE" >> $GITHUB_OUTPUT
            echo "css-size=$CSS_SIZE" >> $GITHUB_OUTPUT
            echo "main-js-size=$MAIN_JS_SIZE" >> $GITHUB_OUTPUT
            echo "main-css-size=$MAIN_CSS_SIZE" >> $GITHUB_OUTPUT

            echo "ðŸ“¦ Bundle Size Analysis:"
            echo "- Total Frontend Size: $FRONTEND_SIZE"
            echo "- Total JS Size: $JS_SIZE"
            echo "- Total CSS Size: $CSS_SIZE"
            echo "- Largest JS File: $MAIN_JS_SIZE"
            echo "- Largest CSS File: $MAIN_CSS_SIZE"

            # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
            find frontend/dist -type f -exec ls -lh {} \; | sort -k5 -hr > bundle-analysis.txt
          else
            echo "âŒ Frontend dist directory not found"
          fi

          echo "::endgroup::"

      - name: ðŸš€ WebPageTest Performance Test
        if: needs.performance-monitoring-setup.outputs.monitoring-scope == 'deep'
        run: |
          echo "::group::WebPageTest Performance Test"

          # è¿™é‡Œå¯ä»¥é›†æˆ WebPageTest API
          echo "ðŸ“ WebPageTest integration would go here"
          echo "âš ï¸ WebPageTest not configured in this example"

          echo "::endgroup::"

      - name: ðŸ“Š Generate Frontend Performance Report
        run: |
          echo "::group::Generating Frontend Performance Report"

          mkdir -p frontend-performance-reports

          cat > frontend-performance-reports/performance-summary.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "performance_score": ${{ steps.lighthouse.outputs.performance-score || '0' }},
            "metrics": {
              "fcp": ${{ steps.lighthouse.outputs.fcp || '0' }},
              "lcp": ${{ steps.lighthouse.outputs.lcp || '0' }},
              "tti": ${{ steps.lighthouse.outputs.tti || '0' }},
              "cls": ${{ steps.lighthouse.outputs.cls || '0' }},
              "fid": ${{ steps.lighthouse.outputs.fid || '0' }}
            },
            "bundle_analysis": {
              "total_size": "${{ steps.bundle-analysis.outputs.frontend-size || '0' }}",
              "js_size": "${{ steps.bundle-analysis.outputs.js-size || '0' }}",
              "css_size": "${{ steps.bundle-analysis.outputs.css-size || '0' }}",
              "main_js_size": "${{ steps.bundle-analysis.outputs.main-js-size || '0' }}",
              "main_css_size": "${{ steps.bundle-analysis.outputs.main-css-size || '0' }}"
            },
            "environment": "${{ needs.performance-monitoring-setup.outputs.test-environment }}",
            "monitoring_scope": "${{ needs.performance-monitoring-setup.outputs.monitoring-scope }}"
          }
          EOF

          echo "âœ… Frontend performance report generated"
          echo "::endgroup::"

      - name: ðŸ“¤ Upload Frontend Performance Reports
        uses: actions/upload-artifact@v4
        with:
          name: frontend-performance-reports
          path: |
            frontend-performance-reports/
            lighthouse-reports/
            bundle-analysis.txt
          retention-days: 30

  # ==========================================
  # åŽç«¯æ€§èƒ½ç›‘æŽ§
  # ==========================================
  backend-performance-monitoring:
    name: âš™ï¸ Backend Performance Monitoring
    runs-on: ubuntu-latest
    needs: performance-monitoring-setup
    if: contains(needs.performance-monitoring-setup.outputs.monitoring-targets, 'backend')

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpassword
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ðŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ðŸ“¦ Install Dependencies
        run: pnpm install --frozen-lockfile

      - name: ðŸ—ï¸ Build Backend
        run: pnpm run backend:build

      - name: ðŸ”§ Setup Test Environment
        run: |
          echo "::group::Setting Up Test Environment"

          # è®¾ç½®çŽ¯å¢ƒå˜é‡
          echo "DATABASE_URL=postgresql://postgres:testpassword@localhost:5432/testdb" >> .env
          echo "REDIS_URL=redis://localhost:6379" >> .env
          echo "NODE_ENV=test" >> .env
          echo "PORT=3001" >> .env

          echo "âœ… Test environment configured"
          echo "::endgroup::"

      - name: ðŸš€ Start Backend Server
        id: backend-server
        run: |
          echo "::group::Starting Backend Server"

          # å¯åŠ¨åŽç«¯æœåŠ¡å™¨
          pnpm run backend:start &
          BACKEND_PID=$!

          # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
          sleep 10

          # æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦å¯åŠ¨æˆåŠŸ
          for i in {1..10}; do
            if curl -f http://localhost:3001/health; then
              echo "âœ… Backend server started successfully (PID: $BACKEND_PID)"
              echo "backend-pid=$BACKEND_PID" >> $GITHUB_OUTPUT
              break
            else
              echo "â³ Waiting for backend server to start... ($i/10)"
              sleep 5
            fi
          done

          echo "::endgroup::"

      - name: âš¡ API Performance Testing
        id: api-performance
        run: |
          echo "::group::API Performance Testing"

          # å®‰è£…æ€§èƒ½æµ‹è¯•å·¥å…·
          npm install -g artillery

          # åˆ›å»º Artillery é…ç½®
          cat > artillery-config.yml << EOF
          config:
            target: 'http://localhost:3001'
            phases:
              - duration: 60
                arrivalRate: 10
                name: "Warm up"
              - duration: 120
                arrivalRate: 25
                name: "Load test"
              - duration: 60
                arrivalRate: 50
                name: "Stress test"
            processor: "./artillery-processor.js"

          scenarios:
            - name: "Health Check Load Test"
              weight: 30
              requests:
                - get:
                    url: "/health"
            - name: "API Endpoints Load Test"
              weight: 50
              requests:
                - get:
                    url: "/api/agents"
                - get:
                    url: "/api/sessions"
            - name: "Chat API Stress Test"
              weight: 20
              requests:
                - post:
                    url: "/api/chat/completions"
                    json:
                      model: "test"
                      messages: [{"role": "user", "content": "Hello, performance test!"}]
          EOF

          # è¿è¡Œæ€§èƒ½æµ‹è¯•
          artillery run artillery-config.yml --output api-performance-results.json

          # åˆ†æžç»“æžœ
          if [ -f "api-performance-results.json" ]; then
            RPS=$(cat api-performance-results.json | jq -r '.aggregate.http.requests' 2>/dev/null || echo "0")
            AVG_LATENCY=$(cat api-performance-results.json | jq -r '.aggregate.latency.mean' 2>/dev/null || echo "0")
            P95_LATENCY=$(cat api-performance-results.json | jq -r '.aggregate.latency.p95' 2>/dev/null || echo "0")
            P99_LATENCY=$(cat api-performance-results.json | jq -r '.aggregate.latency.p99' 2>/dev/null || echo "0")
            ERROR_RATE=$(cat api-performance-results.json | jq -r '.aggregate.errors / .aggregate.http.requests * 100' 2>/dev/null || echo "0")

            echo "rps=$RPS" >> $GITHUB_OUTPUT
            echo "avg-latency=$AVG_LATENCY" >> $GITHUB_OUTPUT
            echo "p95-latency=$P95_LATENCY" >> $GITHUB_OUTPUT
            echo "p99-latency=$P99_LATENCY" >> $GITHUB_OUTPUT
            echo "error-rate=$ERROR_RATE" >> $GITHUB_OUTPUT

            echo "ðŸ“Š API Performance Results:"
            echo "- Requests per Second: $RPS"
            echo "- Average Latency: ${AVG_LATENCY}ms"
            echo "- P95 Latency: ${P95_LATENCY}ms"
            echo "- P99 Latency: ${P99_LATENCY}ms"
            echo "- Error Rate: ${ERROR_RATE}%"
          else
            echo "âŒ API performance results not found"
          fi

          echo "::endgroup::"

      - name: ðŸ“Š Database Performance Testing
        if: needs.performance-monitoring-setup.outputs.monitoring-scope == 'deep'
        run: |
          echo "::group::Database Performance Testing"

          # è¿™é‡Œå¯ä»¥æ·»åŠ æ•°æ®åº“æ€§èƒ½æµ‹è¯•
          echo "ðŸ“ Database performance testing would go here"
          echo "âš ï¸ Database performance testing not configured in this example"

          echo "::endgroup::"

      - name: ðŸ” Memory and CPU Profiling
        if: needs.performance-monitoring-setup.outputs.monitoring-scope == 'deep'
        run: |
          echo "::group::Memory and CPU Profiling"

          # èŽ·å–åŽç«¯è¿›ç¨‹å†…å­˜ä½¿ç”¨æƒ…å†µ
          if [ -n "${{ steps.backend-server.outputs.backend-pid }}" ]; then
            echo "ðŸ“Š Memory usage for backend PID: ${{ steps.backend-server.outputs.backend-pid }}"
            ps -p ${{ steps.backend-server.outputs.backend-pid }} -o pid,ppid,cmd,%mem,%cpu --no-headers || echo "Process not found"
          fi

          echo "ðŸ“ Memory and CPU profiling would go here"
          echo "âš ï¸ Advanced profiling not configured in this example"

          echo "::endgroup::"

      - name: ðŸ“Š Generate Backend Performance Report
        run: |
          echo "::group::Generating Backend Performance Report"

          mkdir -p backend-performance-reports

          cat > backend-performance-reports/performance-summary.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "api_performance": {
              "rps": ${{ steps.api-performance.outputs.rps || '0' }},
              "avg_latency": ${{ steps.api-performance.outputs.avg-latency || '0' }},
              "p95_latency": ${{ steps.api-performance.outputs.p95-latency || '0' }},
              "p99_latency": ${{ steps.api-performance.outputs.p99-latency || '0' }},
              "error_rate": ${{ steps.api-performance.outputs.error-rate || '0' }}
            },
            "environment": "${{ needs.performance-monitoring-setup.outputs.test-environment }}",
            "monitoring_scope": "${{ needs.performance-monitoring-setup.outputs.monitoring-scope }}"
          }
          EOF

          echo "âœ… Backend performance report generated"
          echo "::endgroup::"

      - name: ðŸ›‘ Cleanup Backend Server
        if: always()
        run: |
          if [ -n "${{ steps.backend-server.outputs.backend-pid }}" ]; then
            echo "ðŸ›‘ Stopping backend server..."
            kill ${{ steps.backend-server.outputs.backend-pid }} || echo "Process already stopped"
          fi

      - name: ðŸ“¤ Upload Backend Performance Reports
        uses: actions/upload-artifact@v4
        with:
          name: backend-performance-reports
          path: |
            backend-performance-reports/
            api-performance-results.json
          retention-days: 30

  # ==========================================
  # æ™ºèƒ½åŒ–æ€§èƒ½åˆ†æž
  # ==========================================
  intelligent-performance-analysis:
    name: ðŸ§  Intelligent Performance Analysis
    runs-on: ubuntu-latest
    needs: [performance-monitoring-setup, frontend-performance-monitoring, backend-performance-monitoring]
    if: always() && (needs.frontend-performance-monitoring.result == 'success' || needs.backend-performance-monitoring.result == 'success')

    outputs:
      overall-performance-score: ${{ steps.analysis.outputs.overall-performance-score }}
      performance-status: ${{ steps.analysis.outputs.performance-status }}
      optimization-recommendations: ${{ steps.analysis.outputs.optimization-recommendations }}
      performance-trends: ${{ steps.analysis.outputs.performance-trends }}

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ“Š Download Performance Reports
        uses: actions/download-artifact@v4
        with:
          pattern: "*-performance-reports"
          merge-multiple: true
          path: performance-data/

      - name: ðŸ§  Intelligent Performance Analysis
        id: analysis
        run: |
          echo "::group::Intelligent Performance Analysis"

          # åˆå§‹åŒ–åˆ†æžå˜é‡
          OVERALL_SCORE=100
          PERFORMANCE_STATUS="excellent"
          RECOMMENDATIONS=""
          TRENDS=""

          # åˆ†æžå‰ç«¯æ€§èƒ½
          if [ -f "performance-data/frontend-performance-reports/performance-summary.json" ]; then
            echo "ðŸŒ Analyzing frontend performance..."

            FRONTEND_SCORE=$(cat performance-data/frontend-performance-reports/performance-summary.json | jq -r '.performance_score' 2>/dev/null || echo "0")

            if [ "${FRONTEND_SCORE%.*}" -lt 90 ]; then
              OVERALL_SCORE=$((OVERALL_SCORE - 20))
              PERFORMANCE_STATUS="needs_improvement"
              RECOMMENDATIONS="$RECOMMENDATIONS Optimize frontend performance (Lighthouse score: $FRONTEND_SCORE);"
            fi

            # åˆ†æžåŒ…å¤§å°
            BUNDLE_SIZE=$(cat performance-data/frontend-performance-reports/performance-summary.json | jq -r '.bundle_analysis.total_size' 2>/dev/null || echo "0")
            echo "   Frontend bundle size: $BUNDLE_SIZE"
          fi

          # åˆ†æžåŽç«¯æ€§èƒ½
          if [ -f "performance-data/backend-performance-reports/performance-summary.json" ]; then
            echo "âš™ï¸ Analyzing backend performance..."

            AVG_LATENCY=$(cat performance-data/backend-performance-reports/performance-summary.json | jq -r '.api_performance.avg_latency' 2>/dev/null || echo "0")
            ERROR_RATE=$(cat performance-data/backend-performance-reports/performance-summary.json | jq -r '.api_performance.error_rate' 2>/dev/null || echo "0")
            RPS=$(cat performance-data/backend-performance-reports/performance-summary.json | jq -r '.api_performance.rps' 2>/dev/null || echo "0")

            # è¯„ä¼°APIå“åº”æ—¶é—´
            if [ "${AVG_LATENCY%.*}" -gt 1000 ]; then
              OVERALL_SCORE=$((OVERALL_SCORE - 25))
              PERFORMANCE_STATUS="poor"
              RECOMMENDATIONS="$RECOMMENDATIONS Optimize API response time (avg: ${AVG_LATENCY}ms);"
            elif [ "${AVG_LATENCY%.*}" -gt 500 ]; then
              OVERALL_SCORE=$((OVERALL_SCORE - 15))
              PERFORMANCE_STATUS="needs_improvement"
              RECOMMENDATIONS="$RECOMMENDATIONS Improve API performance (avg: ${AVG_LATENCY}ms);"
            fi

            # è¯„ä¼°é”™è¯¯çŽ‡
            if [ "${ERROR_RATE%.*}" -gt 5 ]; then
              OVERALL_SCORE=$((OVERALL_SCORE - 20))
              PERFORMANCE_STATUS="poor"
              RECOMMENDATIONS="$RECOMMENDATIONS Fix API stability issues (error rate: ${ERROR_RATE}%);"
            elif [ "${ERROR_RATE%.*}" -gt 1 ]; then
              OVERALL_SCORE=$((OVERALL_SCORE - 10))
              PERFORMANCE_STATUS="needs_improvement"
              RECOMMENDATIONS="$RECOMMENDATIONS Reduce API error rate (error rate: ${ERROR_RATE}%);"
            fi

            echo "   API avg latency: ${AVG_LATENCY}ms"
            echo "   API error rate: ${ERROR_RATE}%"
            echo "   API RPS: $RPS"
          fi

          # ç¡®ä¿åˆ†æ•°ä¸ä½ŽäºŽ0
          if [ $OVERALL_SCORE -lt 0 ]; then
            OVERALL_SCORE=0
          fi

          # ç¡®å®šæ€§èƒ½çŠ¶æ€
          if [ $OVERALL_SCORE -ge 90 ]; then
            PERFORMANCE_STATUS="excellent"
          elif [ $OVERALL_SCORE -ge 80 ]; then
            PERFORMANCE_STATUS="good"
          elif [ $OVERALL_SCORE -ge 70 ]; then
            PERFORMANCE_STATUS="acceptable"
          else
            PERFORMANCE_STATUS="poor"
          fi

          # ç”Ÿæˆæ™ºèƒ½å»ºè®®
          if [ -z "$RECOMMENDATIONS" ]; then
            RECOMMENDATIONS="Performance is excellent! Continue current practices."
          else
            RECOMMENDATIONS="$RECOMMENDATIONS Consider performance monitoring and optimization."
          fi

          # è®¾ç½®è¾“å‡º
          echo "overall-performance-score=$OVERALL_SCORE" >> $GITHUB_OUTPUT
          echo "performance-status=$PERFORMANCE_STATUS" >> $GITHUB_OUTPUT
          echo "optimization-recommendations=$RECOMMENDATIONS" >> $GITHUB_OUTPUT
          echo "performance-trends=stable" >> $GITHUB_OUTPUT

          echo "ðŸ“Š Performance Analysis Results:"
          echo "- Overall Score: $OVERALL_SCORE/100"
          echo "- Performance Status: $PERFORMANCE_STATUS"
          echo "- Recommendations: $RECOMMENDATIONS"
          echo "::endgroup::"

      - name: ðŸ“Š Generate Comprehensive Performance Report
        run: |
          echo "::group::Generating Comprehensive Performance Report"

          mkdir -p comprehensive-performance-reports

          cat > comprehensive-performance-reports/performance-analysis.md << EOF
          # LLMChat Intelligent Performance Analysis Report

          ## ðŸ“Š Executive Summary
          - **Overall Performance Score**: ${{ steps.analysis.outputs.overall-performance-score }}/100
          - **Performance Status**: ${{ steps.analysis.outputs.performance-status }}
          - **Monitoring Environment**: ${{ needs.performance-monitoring-setup.outputs.test-environment }}
          - **Monitoring Scope**: ${{ needs.performance-monitoring-setup.outputs.monitoring-scope }}
          - **Analysis Timestamp**: $(date -u)

          ## ðŸŒ Frontend Performance Analysis

          ### Lighthouse Metrics
          $(if [ -f "performance-data/frontend-performance-reports/performance-summary.json" ]; then
            echo "- **Performance Score**: $(cat performance-data/frontend-performance-reports/performance-summary.json | jq -r '.performance_score' || 'N/A')"
            echo "- **First Contentful Paint**: $(cat performance-data/frontend-performance-reports/performance-summary.json | jq -r '.metrics.fcp' || 'N/A')ms"
            echo "- **Largest Contentful Paint**: $(cat performance-data/frontend-performance-reports/performance-summary.json | jq -r '.metrics.lcp' || 'N/A')ms"
            echo "- **Time to Interactive**: $(cat performance-data/frontend-performance-reports/performance-summary.json | jq -r '.metrics.tti' || 'N/A')ms"
            echo "- **Cumulative Layout Shift**: $(cat performance-data/frontend-performance-reports/performance-summary.json | jq -r '.metrics.cls' || 'N/A')"
            echo "- **First Input Delay**: $(cat performance-data/frontend-performance-reports/performance-summary.json | jq -r '.metrics.fid' || 'N/A')ms"
          else
            echo "- Frontend performance data not available"
          fi)

          ### Bundle Analysis
          $(if [ -f "performance-data/frontend-performance-reports/performance-summary.json" ]; then
            echo "- **Total Bundle Size**: $(cat performance-data/frontend-performance-reports/performance-summary.json | jq -r '.bundle_analysis.total_size' || 'N/A')"
            echo "- **JS Bundle Size**: $(cat performance-data/frontend-performance-reports/performance-summary.json | jq -r '.bundle_analysis.js_size' || 'N/A')"
            echo "- **CSS Bundle Size**: $(cat performance-data/frontend-performance-reports/performance-summary.json | jq -r '.bundle_analysis.css_size' || 'N/A')"
          else
            echo "- Bundle analysis data not available"
          fi)

          ## âš™ï¸ Backend Performance Analysis

          ### API Performance Metrics
          $(if [ -f "performance-data/backend-performance-reports/performance-summary.json" ]; then
            echo "- **Requests per Second**: $(cat performance-data/backend-performance-reports/performance-summary.json | jq -r '.api_performance.rps' || 'N/A')"
            echo "- **Average Response Time**: $(cat performance-data/backend-performance-reports/performance-summary.json | jq -r '.api_performance.avg_latency' || 'N/A')ms"
            echo "- **P95 Response Time**: $(cat performance-data/backend-performance-reports/performance-summary.json | jq -r '.api_performance.p95_latency' || 'N/A')ms"
            echo "- **P99 Response Time**: $(cat performance-data/backend-performance-reports/performance-summary.json | jq -r '.api_performance.p99_latency' || 'N/A')ms"
            echo "- **Error Rate**: $(cat performance-data/backend-performance-reports/performance-summary.json | jq -r '.api_performance.error_rate' || 'N/A')%"
          else
            echo "- Backend performance data not available"
          fi)

          ## ðŸ§  Intelligent Recommendations

          ${{ steps.analysis.outputs.optimization-recommendations }}

          ### Optimization Priorities
          ${{ steps.analysis.outputs.overall-performance-score >= 90 && 'ðŸŒŸ **High Priority**: Maintain current performance standards' || '' }}
          ${{ steps.analysis.outputs.overall-performance-score >= 80 && steps.analysis.outputs.overall-performance-score < 90 && 'âœ… **Medium Priority**: Implement minor optimizations' || '' }}
          ${{ steps.analysis.outputs.overall-performance-score >= 70 && steps.analysis.outputs.overall-performance-score < 80 && 'âš ï¸ **High Priority**: Address performance bottlenecks' || '' }}
          ${{ steps.analysis.outputs.overall-performance-score < 70 && 'ðŸš¨ **Critical Priority**: Immediate performance optimization required' || '' }}

          ### Specific Recommendations
          - **Frontend Optimization**: Implement code splitting, lazy loading, and bundle optimization
          - **Backend Optimization**: Focus on API response time and error rate reduction
          - **Database Optimization**: Consider query optimization and indexing strategies
          - **Caching Strategy**: Implement appropriate caching mechanisms
          - **Monitoring Enhancement**: Set up comprehensive performance monitoring

          ## ðŸ“ˆ Performance Trends

          - **Current Status**: ${{ steps.analysis.outputs.performance-trends }}
          - **Trend Analysis**: Based on current metrics, performance is ${{ steps.analysis.outputs.performance-status }}
          - **Expected Impact**: Implementing recommended optimizations should improve performance score by 10-20 points

          ## ðŸŽ¯ Next Steps

          1. **Immediate Actions** (if score < 80)
              - Address critical performance bottlenecks
              - Implement high-impact optimizations
              - Set up performance monitoring alerts

          2. **Short-term Goals** (next 2 weeks)
              - Implement bundle size optimization
              - Improve API response times
              - Enhance error handling

          3. **Long-term Goals** (next month)
              - Implement advanced caching strategies
              - Set up comprehensive performance monitoring
              - Optimize database queries

          ---
          *Report generated by LLMChat Intelligent Performance Monitoring System*
          *Generated on $(date -u)*
          EOF

          echo "âœ… Comprehensive performance report generated"
          echo "::endgroup::"

      - name: ðŸ“¤ Upload Comprehensive Performance Report
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-performance-report
          path: comprehensive-performance-reports/
          retention-days: 90

      - name: ðŸš« Performance Threshold Enforcement
        if: steps.analysis.outputs.overall-performance-score < 70
        run: |
          echo "âŒ Performance score below threshold - requires attention"
          echo "ðŸ“Š Performance Score: ${{ steps.analysis.outputs.overall-performance-score }}/100"
          echo "ðŸš¦ Performance Status: ${{ steps.analysis.outputs.performance-status }}"
          echo "ðŸ’¡ Recommendations: ${{ steps.analysis.outputs.optimization-recommendations }}"
          exit 1

  # ==========================================
  # æ€§èƒ½ä¼˜åŒ–å»ºè®®ç”Ÿæˆ
  # ==========================================
  optimization-recommendations:
    name: ðŸ’¡ Performance Optimization Recommendations
    runs-on: ubuntu-latest
    needs: [performance-monitoring-setup, intelligent-performance-analysis]
    if: always() && needs.intelligent-performance-analysis.result == 'success' && needs.performance-monitoring-setup.outputs.optimization-enabled == 'true'

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ“¥ Download Performance Reports
        uses: actions/download-artifact@v4
        with:
          name: comprehensive-performance-report
          path: performance-reports/
          merge-multiple: true

      - name: ðŸ’¡ Generate Optimization Recommendations
        run: |
          echo "::group::Generating Optimization Recommendations"

          mkdir -p optimization-recommendations

          # åˆ›å»ºä¼˜åŒ–å»ºè®®æ–‡æ¡£
          cat > optimization-recommendations/optimization-plan.md << EOF
          # LLMChat Performance Optimization Plan

          ## ðŸ“Š Current Performance Status
          - **Overall Score**: ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score }}/100
          - **Status**: ${{ needs.intelligent-performance-analysis.outputs.performance-status }}

          ## ðŸŽ¯ Optimization Priorities

          ### High Priority (Critical Issues)
          ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score < 70 && '1. Address critical performance bottlenecks immediately' || '' }}
          ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score < 70 && '2. Implement essential performance optimizations' || '' }}
          ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score < 70 && '3. Set up performance monitoring and alerting' || '' }}

          ### Medium Priority (Important Improvements)
          ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score >= 70 && needs.intelligent-performance-analysis.outputs.overall-performance-score < 90 && '1. Implement bundle size optimization' || '' }}
          ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score >= 70 && needs.intelligent-performance-analysis.outputs.overall-performance-score < 90 && '2. Improve API response times' || '' }}
          ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score >= 70 && needs.intelligent-performance-analysis.outputs.overall-performance-score < 90 && '3. Enhance caching mechanisms' || '' }}

          ### Low Priority (Nice to Have)
          ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score >= 90 && '1. Fine-tune performance metrics' || '' }}
          ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score >= 90 && '2. Implement advanced optimization techniques' || '' }}
          ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score >= 90 && '3. Consider performance monitoring enhancements' || '' }}

          ## ðŸŒ Frontend Optimizations

          ### Bundle Size Optimization
          - Implement code splitting with dynamic imports
          - Remove unused dependencies and code
          - Optimize images and static assets
          - Implement tree shaking for dead code elimination

          ### Loading Performance
          - Implement lazy loading for non-critical components
          - Add preloading for critical resources
          - Optimize initial JavaScript payload
          - Implement service worker caching

          ### Runtime Performance
          - Optimize React component re-renders
          - Implement virtual scrolling for long lists
          - Use React.memo for component memoization
          - Optimize state management patterns

          ## âš™ï¸ Backend Optimizations

          ### API Performance
          - Implement response caching strategies
          - Optimize database queries and indexing
          - Use connection pooling for database connections
          - Implement request batching where appropriate

          ### Error Handling
          - Implement comprehensive error logging
          - Add circuit breakers for external services
          - Optimize error response formats
          - Implement graceful degradation strategies

          ### Resource Management
          - Implement memory optimization techniques
          - Optimize CPU-intensive operations
          - Use background job processing for heavy tasks
          - Implement rate limiting and throttling

          ## ðŸ—„ï¸ Database Optimizations

          ### Query Optimization
          - Analyze and optimize slow queries
          - Implement appropriate indexing strategies
          - Use query result caching
          - Optimize database connection management

          ### Data Management
          - Implement data archiving strategies
          - Optimize table structures and relationships
          - Use database-specific optimizations
          - Implement backup and recovery strategies

          ## ðŸ“Š Monitoring and Analytics

          ### Performance Monitoring
          - Set up comprehensive performance monitoring
          - Implement real-time performance metrics
          - Create performance dashboards and alerts
          - Track performance trends over time

          ### User Experience Metrics
          - Monitor Core Web Vitals
          - Track user interaction metrics
          - Implement A/B testing for performance changes
          - Collect user feedback on performance

          ## ðŸš€ Implementation Timeline

          ### Phase 1 (Week 1-2): Critical Issues
          - Address immediate performance bottlenecks
          - Implement essential optimizations
          - Set up basic monitoring

          ### Phase 2 (Week 3-4): Important Improvements
          - Implement bundle optimization
          - Improve API performance
          - Enhance caching mechanisms

          ### Phase 3 (Week 5-8): Advanced Optimizations
          - Implement advanced monitoring
          - Fine-tune performance metrics
          - Optimize user experience

          ## ðŸ“ˆ Success Metrics

          ### Performance Targets
          - Lighthouse Performance Score: â‰¥ 90
          - API Response Time: â‰¤ 500ms (average)
          - Error Rate: â‰¤ 1%
          - Bundle Size: â‰¤ 1MB (compressed)

          ### Monitoring Metrics
          - Page Load Time: â‰¤ 3s
          - Time to Interactive: â‰¤ 2s
          - Cumulative Layout Shift: â‰¤ 0.1
          - First Input Delay: â‰¤ 100ms

          ## ðŸ”§ Tools and Technologies

          ### Frontend Tools
          - Lighthouse CI for automated performance testing
          - Webpack Bundle Analyzer for bundle analysis
          - Chrome DevTools Performance Profiler
          - React DevTools Profiler

          ### Backend Tools
          - Artillery for API load testing
          - APM tools (New Relic, DataDog, etc.)
          - Database query analyzers
          - Performance monitoring platforms

          ## ðŸ“š Resources and Documentation

          - [Web Performance Best Practices](https://web.dev/performance/)
          - [React Performance Optimization](https://reactjs.org/docs/optimizing-performance.html)
          - [Node.js Performance Tuning](https://nodejs.org/en/docs/guides/simple-profiling.html)
          - [Database Performance Optimization](https://www.postgresql.org/docs/performance-tips.html)

          ---
          *Optimization plan generated by LLMChat Performance Monitoring System*
          *Generated on $(date -u)*
          EOF

          echo "âœ… Optimization recommendations generated"
          echo "::endgroup::"

      - name: ðŸ“Š Generate Optimization Tasks
        run: |
          echo "::group::Generating Optimization Tasks"

          # åˆ›å»ºä¼˜åŒ–ä»»åŠ¡æ¸…å•
          cat > optimization-recommendations/optimization-tasks.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "performance_score": ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score }},
            "performance_status": "${{ needs.intelligent-performance-analysis.outputs.performance-status }}",
            "tasks": [
              {
                "id": "opt-001",
                "title": "Implement bundle size optimization",
                "priority": "high",
                "estimated_effort": "2 days",
                "description": "Reduce frontend bundle size through code splitting and tree shaking",
                "impact": "20-30% performance improvement"
              },
              {
                "id": "opt-002",
                "title": "Optimize API response times",
                "priority": "high",
                "estimated_effort": "3 days",
                "description": "Improve backend API performance through caching and query optimization",
                "impact": "15-25% performance improvement"
              },
              {
                "id": "opt-003",
                "title": "Implement comprehensive performance monitoring",
                "priority": "medium",
                "estimated_effort": "1 week",
                "description": "Set up performance monitoring and alerting systems",
                "impact": "10-15% performance improvement"
              }
            ],
            "environment": "${{ needs.performance-monitoring-setup.outputs.test-environment }}"
          }
          EOF

          echo "âœ… Optimization tasks generated"
          echo "::endgroup::"

      - name: ðŸ“¤ Upload Optimization Recommendations
        uses: actions/upload-artifact@v4
        with:
          name: optimization-recommendations
          path: optimization-recommendations/
          retention-days: 90

      - name: ðŸ’¬ Create Optimization Issues (Optional)
        if: needs.intelligent-performance-analysis.outputs.overall-performance-score < 80
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            try {
              const planPath = 'optimization-recommendations/optimization-plan.md';
              if (fs.existsSync(planPath)) {
                const plan = fs.readFileSync(planPath, 'utf8');
                const score = ${{ needs.intelligent-performance-analysis.outputs.overall-performance-score }};

                // Create GitHub issue for optimization
                await github.rest.issues.create({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  title: `Performance Optimization Required - Score: ${score}/100`,
                  body: `## ðŸš¨ Performance Optimization Required

                  **Current Performance Score**: ${score}/100
                  **Status**: ${{ needs.intelligent-performance-analysis.outputs.performance-status }}

                  ## ðŸ“‹ Optimization Plan

                  ${plan}

                  ## ðŸŽ¯ Next Steps

                  1. Review the optimization recommendations
                  2. Create implementation tasks
                  3. Track progress regularly
                  4. Monitor performance improvements

                  ---
                  *This issue was automatically generated by the Performance Monitoring System*`,
                  labels: ['performance', 'optimization', 'priority-high']
                });

                console.log('âœ… Performance optimization issue created');
              }
            } catch (error) {
              console.log('âŒ Error creating issue:', error.message);
            }