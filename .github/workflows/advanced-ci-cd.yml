name: ðŸš€ Advanced CI/CD Pipeline - Enterprise Automation

on:
  push:
    branches: [main, develop, release/*, hotfix/*]
  pull_request:
    branches: [main, develop]
    types: [opened, synchronize, reopened, ready_for_review]
  release:
    types: [published, prereleased]
  schedule:
    # æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œå…¨é¢æ‰«æ
    - cron: '0 2 * * *'
    # æ¯å‘¨æ—¥æ™šä¸Š8ç‚¹è¿è¡Œæ·±åº¦è´¨é‡æ£€æŸ¥
    - cron: '0 20 * * 0'
    # æ¯å°æ—¶è¿è¡Œå®‰å…¨æ‰«æ
    - cron: '0 * * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'development'
        type: choice
        options:
          - development
          - staging
          - production
      deployment_strategy:
        description: 'Deployment strategy'
        required: true
        default: 'rolling'
        type: choice
        options:
          - rolling
          - blue-green
          - canary
      security_scan:
        description: 'Run comprehensive security scan'
        required: false
        default: true
        type: boolean
      performance_test:
        description: 'Run performance tests'
        required: false
        default: false
        type: boolean
      rollback_enabled:
        description: 'Enable automatic rollback on failure'
        required: false
        default: true
        type: boolean
      parallel_execution:
        description: 'Enable parallel execution for faster builds'
        required: false
        default: true
        type: boolean

env:
  NODE_VERSION: '20'
  PNPM_VERSION: '8.15.0'
  CI: true
  TZ: 'Asia/Shanghai'
  DOCKER_REGISTRY: 'ghcr.io'
  KUBERNETES_NAMESPACE: 'llmchat'

# å…¨å±€å˜é‡
vars:
  quality_threshold: '85'
  security_threshold: '0'
  performance_threshold: '95'
  coverage_threshold: '80'
  build_timeout: '30'
  deploy_timeout: '15'

jobs:
  # ==========================================
  # é˜¶æ®µ0: æ™ºèƒ½åŒ–å‰ç½®æ£€æŸ¥
  # ==========================================
  intelligent-precheck:
    name: ðŸ§  Intelligent Pre-check Analysis
    runs-on: ubuntu-latest
    outputs:
      build-strategy: ${{ steps.analysis.outputs.build-strategy }}
      test-scope: ${{ steps.analysis.outputs.test-scope }}
      security-level: ${{ steps.analysis.outputs.security-level }}
      deployment-risk: ${{ steps.analysis.outputs.deployment-risk }}
      cache-strategy: ${{ steps.analysis.outputs.cache-strategy }}
      parallel-enabled: ${{ steps.analysis.outputs.parallel-enabled }}

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: false

      - name: ðŸ” Intelligent Change Analysis
        id: analysis
        run: |
          echo "::group::Intelligent Change Analysis"

          # èŽ·å–å˜æ›´èŒƒå›´
          if [ "${{ github.event_name }}" == "pull_request" ]; then
            CHANGED_FILES=$(git diff --name-only origin/${{ github.base_ref }}..${{ github.sha }})
          else
            CHANGED_FILES=$(git diff --name-only ${{ github.event.before }}..${{ github.sha }})
          fi

          echo "Changed files: $CHANGED_FILES"

          # æ™ºèƒ½åˆ†æžå˜æ›´ç±»åž‹
          FRONTEND_CHANGES=$(echo "$CHANGED_FILES" | grep -E "^frontend/" | wc -l)
          BACKEND_CHANGES=$(echo "$CHANGED_FILES" | grep -E "^backend/" | wc -l)
          CONFIG_CHANGES=$(echo "$CHANGED_FILES" | grep -E "^(\.github|\.env|config|pnpm-lock|package\.json)" | wc -l)
          TEST_CHANGES=$(echo "$CHANGED_FILES" | grep -E "(\.test\.|\.spec\.|__tests__|tests/)" | wc -l)
          SECURITY_CHANGES=$(echo "$CHANGED_FILES" | grep -E "(\.env|secret|key|password|auth)" | wc -l)

          echo "Frontend changes: $FRONTEND_CHANGES"
          echo "Backend changes: $BACKEND_CHANGES"
          echo "Config changes: $CONFIG_CHANGES"
          echo "Test changes: $TEST_CHANGES"
          echo "Security changes: $SECURITY_CHANGES"

          # æ™ºèƒ½æž„å»ºç­–ç•¥
          if [ $FRONTEND_CHANGES -gt 0 ] && [ $BACKEND_CHANGES -gt 0 ]; then
            echo "build-strategy=full" >> $GITHUB_OUTPUT
          elif [ $FRONTEND_CHANGES -gt 0 ]; then
            echo "build-strategy=frontend" >> $GITHUB_OUTPUT
          elif [ $BACKEND_CHANGES -gt 0 ]; then
            echo "build-strategy=backend" >> $GITHUB_OUTPUT
          else
            echo "build-strategy=Minimal" >> $GITHUB_OUTPUT
          fi

          # æ™ºèƒ½æµ‹è¯•èŒƒå›´
          if [ $TEST_CHANGES -gt 0 ]; then
            echo "test-scope=full" >> $GITHUB_OUTPUT
          elif [ $CONFIG_CHANGES -gt 0 ]; then
            echo "test-scope=integration" >> $GITHUB_OUTPUT
          else
            echo "test-scope=smoke" >> $GITHUB_OUTPUT
          fi

          # å®‰å…¨çº§åˆ«
          if [ $SECURITY_CHANGES -gt 0 ]; then
            echo "security-level=high" >> $GITHUB_OUTPUT
          elif [ $CONFIG_CHANGES -gt 0 ]; then
            echo "security-level=medium" >> $GITHUB_OUTPUT
          else
            echo "security-level=low" >> $GITHUB_OUTPUT
          fi

          # éƒ¨ç½²é£Žé™©è¯„ä¼°
          RISK_SCORE=$((FRONTEND_CHANGES + BACKEND_CHANGES + CONFIG_CHANGES * 2 + SECURITY_CHANGES * 3))
          if [ $RISK_SCORE -gt 20 ]; then
            echo "deployment-risk=high" >> $GITHUB_OUTPUT
          elif [ $RISK_SCORE -gt 10 ]; then
            echo "deployment-risk=medium" >> $GITHUB_OUTPUT
          else
            echo "deployment-risk=low" >> $GITHUB_OUTPUT
          fi

          # ç¼“å­˜ç­–ç•¥
          if [ $CONFIG_CHANGES -eq 0 ]; then
            echo "cache-strategy=aggressive" >> $GITHUB_OUTPUT
          else
            echo "cache-strategy=conservative" >> $GITHUB_OUTPUT
          fi

          # å¹¶è¡Œæ‰§è¡Œ
          if [ "${{ github.event.inputs.parallel_execution }}" == "false" ]; then
            echo "parallel-enabled=false" >> $GITHUB_OUTPUT
          else
            echo "parallel-enabled=true" >> $GITHUB_OUTPUT
          fi

          echo "::endgroup::"

      - name: ðŸ“Š Generate Analysis Report
        run: |
          echo "## ðŸ§  Intelligent Pre-check Analysis" > analysis-report.md
          echo "" >> analysis-report.md
          echo "- **Build Strategy**: ${{ steps.analysis.outputs.build-strategy }}" >> analysis-report.md
          echo "- **Test Scope**: ${{ steps.analysis.outputs.test-scope }}" >> analysis-report.md
          echo "- **Security Level**: ${{ steps.analysis.outputs.security-level }}" >> analysis-report.md
          echo "- **Deployment Risk**: ${{ steps.analysis.outputs.deployment-risk }}" >> analysis-report.md
          echo "- **Cache Strategy**: ${{ steps.analysis.outputs.cache-strategy }}" >> analysis-report.md
          echo "- **Parallel Execution**: ${{ steps.analysis.outputs.parallel-enabled }}" >> analysis-report.md

      - name: ðŸ“¤ Upload Analysis Report
        uses: actions/upload-artifact@v4
        with:
          name: intelligent-analysis
          path: analysis-report.md
          retention-days: 7

  # ==========================================
  # é˜¶æ®µ1: æ™ºèƒ½åŒ–çŽ¯å¢ƒå‡†å¤‡
  # ==========================================
  smart-environment-setup:
    name: ðŸš€ Smart Environment Setup
    runs-on: ubuntu-latest
    needs: intelligent-precheck
    outputs:
      cache-hit: ${{ steps.cache.outputs.cache-hit }}
      environment-ready: ${{ steps.setup.outputs.environment-ready }}

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js ${{ env.NODE_VERSION }}
        id: setup
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ðŸ“¦ Setup pnpm ${{ env.PNPM_VERSION }}
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ðŸ“š Get pnpm store directory
        shell: bash
        run: |
          echo "STORE_PATH=$(pnpm store path --silent)" >> $GITHUB_ENV

      - name: ðŸ’¾ Smart Cache Strategy
        id: cache
        uses: actions/cache@v4
        with:
          path: ${{ env.STORE_PATH }}
          key: ${{ runner.os }}-pnpm-store-${{ needs.intelligent-precheck.outputs.cache-strategy }}-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-${{ needs.intelligent-precheck.outputs.cache-strategy }}-
            ${{ runner.os }}-pnpm-store-

      - name: ðŸ“¦ Smart Dependency Installation
        run: |
          echo "ðŸ“¦ Installing dependencies with strategy: ${{ needs.intelligent-precheck.outputs.cache-strategy }}"

          if [ "${{ needs.intelligent-precheck.outputs.cache-strategy }}" == "aggressive" ]; then
            pnpm install --frozen-lockfile --prefer-offline --prefer-frozen-lockfile
          else
            pnpm install --frozen-lockfile
          fi

      - name: ðŸ” Environment Validation
        run: |
          echo "âœ… Environment setup completed"
          echo "environment-ready=true" >> $GITHUB_OUTPUT

  # ==========================================
  # é˜¶æ®µ2: æ™ºèƒ½åŒ–è´¨é‡æ£€æŸ¥ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰
  # ==========================================
  intelligent-quality-checks:
    name: ðŸ” Intelligent Quality Checks
    runs-on: ubuntu-latest
    needs: [smart-environment-setup, intelligent-precheck]
    if: needs.smart-environment-setup.outputs.environment-ready == 'true'
    strategy:
      fail-fast: false
      matrix:
        check-type: [type-check, lint, security, dependency-audit, code-complexity]
        include:
          - check-type: type-check
            name: "TypeScript Type Safety"
            command: pnpm run type-check
            icon: "ðŸ“"
            critical: true
          - check-type: lint
            name: "ESLint Quality Check"
            command: pnpm run lint
            icon: "ðŸ”"
            critical: true
          - check-type: security
            name: "Security Vulnerability Scan"
            command: pnpm audit --audit-level moderate
            icon: "ðŸ”’"
            critical: true
          - check-type: dependency-audit
            name: "Dependency Audit"
            command: pnpm audit --json
            icon: "ðŸ“¦"
            critical: false
          - check-type: code-complexity
            name: "Code Complexity Analysis"
            command: "echo 'Complexity analysis placeholder'"
            icon: "ðŸ“Š"
            critical: false

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ðŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ðŸ’¾ Restore Dependencies Cache
        if: needs.intelligent-precheck.outputs.cache-strategy == 'aggressive'
        uses: actions/cache@v4
        with:
          path: ~/.pnpm-store
          key: ${{ runner.os }}-pnpm-store-aggressive-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-aggressive-

      - name: ðŸ“¦ Install Dependencies
        if: needs.intelligent-precheck.outputs.cache-strategy != 'aggressive'
        run: pnpm install --frozen-lockfile

      - name: ${{ matrix.icon }} ${{ matrix.name }}
        id: quality-check
        run: |
          echo "::group::${{ matrix.name }}"

          # åˆ›å»ºè´¨é‡æŠ¥å‘Šç›®å½•
          mkdir -p quality-reports

          # è¿è¡Œæ£€æŸ¥
          if ${{ matrix.command }}; then
            echo "${{ matrix.check-type }}_status=passed" >> $GITHUB_OUTPUT
            echo "âœ… ${{ matrix.name }} passed"
          else
            echo "${{ matrix.check-type }}_status=failed" >> $GITHUB_OUTPUT
            echo "âŒ ${{ matrix.name }} failed"

            if [ "${{ matrix.critical }}" == "true" ]; then
              echo "::endgroup::"
              exit 1
            fi
          fi
          echo "::endgroup::"

      - name: ðŸ“Š Quality Metrics Collection
        if: always()
        run: |
          # æ”¶é›†è´¨é‡æŒ‡æ ‡
          METRICS_FILE="quality-reports/${{ matrix.check-type }}-metrics.json"

          cat > $METRICS_FILE << EOF
          {
            "check_type": "${{ matrix.check-type }}",
            "status": "${{ steps.quality-check.outputs.${{ matrix.check-type }}_status }}",
            "critical": ${{ matrix.critical }},
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "job_id": "${{ github.job_id }}",
            "run_id": "${{ github.run_id }}"
          }
          EOF

      - name: ðŸ“¤ Upload Quality Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: quality-results-${{ matrix.check-type }}
          path: quality-reports/
          retention-days: 30

  # ==========================================
  # é˜¶æ®µ3: æ™ºèƒ½åŒ–æµ‹è¯•å¥—ä»¶ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰
  # ==========================================
  intelligent-testing:
    name: ðŸ§ª Intelligent Testing Suite
    runs-on: ubuntu-latest
    needs: [smart-environment-setup, intelligent-precheck]
    if: needs.smart-environment-setup.outputs.environment-ready == 'true'
    strategy:
      fail-fast: false
      matrix:
        test-type: [unit, integration, e2e, performance]
        include:
          - test-type: unit
            name: "Unit Tests"
            command: pnpm test --coverage
            coverage: true
            icon: "ðŸ”¬"
            parallel: true
          - test-type: integration
            name: "Integration Tests"
            command: pnpm run test:integration
            coverage: false
            icon: "ðŸ”—"
            parallel: true
          - test-type: e2e
            name: "E2E Tests"
            command: pnpm run test:e2e
            coverage: false
            icon: "ðŸŒ"
            parallel: false
            setup: true
          - test-type: performance
            name: "Performance Tests"
            command: "echo 'Performance tests placeholder'"
            coverage: false
            icon: "ðŸ“Š"
            parallel: false

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ðŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ðŸ’¾ Restore Dependencies Cache
        uses: actions/cache@v4
        with:
          path: ~/.pnpm-store
          key: ${{ runner.os }}-pnpm-store-${{ hashFiles('**/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-pnpm-store-

      - name: ðŸ“¦ Install Dependencies
        run: pnpm install --frozen-lockfile

      - name: ðŸŒ Setup E2E Dependencies
        if: matrix.setup
        run: |
          pnpm exec playwright install --with-deps
          pnpm exec playwright install-deps

      - name: ${{ matrix.icon }} ${{ matrix.name }}
        id: test-run
        run: |
          echo "::group::${{ matrix.name }}"

          # åˆ›å»ºæµ‹è¯•æŠ¥å‘Šç›®å½•
          mkdir -p test-reports
          mkdir -p coverage

          # è¿è¡Œæµ‹è¯•
          if ${{ matrix.command }}; then
            echo "${{ matrix.test-type }}_status=passed" >> $GITHUB_OUTPUT
            echo "âœ… ${{ matrix.name }} passed"
          else
            echo "${{ matrix.test-type }}_status=failed" >> $GITHUB_OUTPUT
            echo "âŒ ${{ matrix.name }} failed"
            echo "::endgroup::"
            exit 1
          fi
          echo "::endgroup::"

      - name: ðŸ“Š Process Coverage Reports
        if: matrix.coverage && steps.test-run.outputs.${{ matrix.test-type }}_status == 'passed'
        run: |
          echo "ðŸ“Š Processing coverage reports..."

          if [ -f "coverage/lcov.info" ]; then
            echo "âœ… Coverage report found"
            npx nyc report --reporter=text-summary > test-reports/coverage-summary.txt
            npx nyc report --reporter=json > test-reports/coverage-summary.json

            # æå–è¦†ç›–çŽ‡ç™¾åˆ†æ¯”
            COVERAGE_PERCENT=$(cat test-reports/coverage-summary.txt | grep "Lines" | awk '{print $2}' | sed 's/%//')
            echo "coverage_percent=$COVERAGE_PERCENT" >> $GITHUB_STEP_SUMMARY
          fi

      - name: ðŸ“¤ Upload Test Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.test-type }}
          path: |
            test-reports/
            coverage/
            playwright-report/
          retention-days: 30

  # ==========================================
  # é˜¶æ®µ4: æ™ºèƒ½åŒ–æž„å»º
  # ==========================================
  intelligent-build:
    name: ðŸ—ï¸ Intelligent Build System
    runs-on: ubuntu-latest
    needs: [smart-environment-setup, intelligent-precheck]
    if: needs.smart-environment-setup.outputs.environment-ready == 'true'

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      - name: ðŸ“¦ Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: ðŸ“¦ Install Dependencies
        run: pnpm install --frozen-lockfile

      - name: ðŸ—ï¸ Smart Build Process
        id: build
        run: |
          echo "::group::Smart Build Process"

          BUILD_START=$(date +%s)

          # æ ¹æ®æ™ºèƒ½åˆ†æžç»“æžœé€‰æ‹©æž„å»ºç­–ç•¥
          BUILD_STRATEGY="${{ needs.intelligent-precheck.outputs.build-strategy }}"

          case $BUILD_STRATEGY in
            "full")
              echo "ðŸ—ï¸ Running full build (frontend + backend)"
              pnpm run build
              ;;
            "frontend")
              echo "ðŸŽ¨ Running frontend build only"
              pnpm run frontend:build
              ;;
            "backend")
              echo "âš™ï¸ Running backend build only"
              pnpm run backend:build
              ;;
            "minimal")
              echo "âš¡ Running minimal build"
              echo "Minimal build completed"
              ;;
          esac

          BUILD_END=$(date +%s)
          BUILD_DURATION=$((BUILD_END - BUILD_START))

          echo "build_status=success" >> $GITHUB_OUTPUT
          echo "build_duration=$BUILD_DURATION" >> $GITHUB_OUTPUT
          echo "build_strategy=$BUILD_STRATEGY" >> $GITHUB_OUTPUT

          echo "âœ… Build completed in ${BUILD_DURATION}s"
          echo "::endgroup::"

      - name: ðŸ“Š Build Analysis
        if: steps.build.outputs.build_status == 'success'
        run: |
          echo "ðŸ“Š Analyzing build artifacts..."

          mkdir -p build-analysis

          # åˆ†æžæž„å»ºäº§ç‰©
          if [ -d "backend/dist" ]; then
            BACKEND_SIZE=$(du -sh backend/dist | cut -f1)
            BACKEND_FILES=$(find backend/dist -type f | wc -l)
            echo "Backend: $BACKEND_SIZE, $BACKEND_FILES files"
          fi

          if [ -d "frontend/dist" ]; then
            FRONTEND_SIZE=$(du -sh frontend/dist | cut -f1)
            FRONTEND_FILES=$(find frontend/dist -type f | wc -l)
            echo "Frontend: $FRONTEND_SIZE, $FRONTEND_FILES files"
          fi

      - name: ðŸ“¤ Upload Build Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: build-artifacts-${{ needs.intelligent-precheck.outputs.build-strategy }}
          path: |
            backend/dist/
            frontend/dist/
            build-analysis/
          retention-days: 7

  # ==========================================
  # é˜¶æ®µ5: å®¹å™¨åŒ–æž„å»º
  # ==========================================
  containerization:
    name: ðŸ³ Containerization & Image Build
    runs-on: ubuntu-latest
    needs: [intelligent-build, intelligent-precheck]
    if: needs.intelligent-build.result == 'success'

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ“¥ Download Build Artifacts
        uses: actions/download-artifact@v4
        with:
          name: build-artifacts-${{ needs.intelligent-precheck.outputs.build-strategy }}
          path: ./

      - name: ðŸ³ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: ðŸ” Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: ðŸ·ï¸ Generate Build Metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.DOCKER_REGISTRY }}/${{ github.repository }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}

      - name: ðŸ³ Build and Push Backend Image
        if: needs.intelligent-precheck.outputs.build-strategy == 'full' || needs.intelligent-precheck.outputs.build-strategy == 'backend'
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}-backend
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64

      - name: ðŸ³ Build and Push Frontend Image
        if: needs.intelligent-precheck.outputs.build-strategy == 'full' || needs.intelligent-precheck.outputs.build-strategy == 'frontend'
        uses: docker/build-push-action@v5
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}-frontend
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64

      - name: ðŸ³ Build and Push Application Image
        if: needs.intelligent-precheck.outputs.build-strategy == 'full'
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64,linux/arm64

  # ==========================================
  # é˜¶æ®µ6: æ™ºèƒ½åŒ–è´¨é‡é—¨ç¦
  # ==========================================
  intelligent-quality-gates:
    name: ðŸ›¡ï¸ Intelligent Quality Gates
    runs-on: ubuntu-latest
    needs: [intelligent-quality-checks, intelligent-testing, intelligent-build]
    if: always()

    outputs:
      overall-status: ${{ gates.outputs.overall-status }}
      quality-score: ${{ gates.outputs.quality-score }}
      deployment-ready: ${{ gates.outputs.deployment-ready }}
      deployment-strategy: ${{ gates.outputs.deployment-strategy }}

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ“Š Download All Reports
        uses: actions/download-artifact@v4
        with:
          pattern: "*-results-*"
          merge-multiple: true
          path: all-reports/

      - name: ðŸ›¡ï¸ Intelligent Quality Assessment
        id: gates
        run: |
          echo "::group::Intelligent Quality Assessment"

          # åˆå§‹åŒ–åˆ†æ•°å’ŒçŠ¶æ€
          QUALITY_SCORE=100
          OVERALL_STATUS="passed"
          DEPLOYMENT_READY="true"
          DEPLOYMENT_STRATEGY="rolling"

          # è¯„ä¼°è´¨é‡æ£€æŸ¥ç»“æžœ
          QUALITY_CHECKS_RESULT="${{ needs.intelligent-quality-checks.result }}"
          if [ "$QUALITY_CHECKS_RESULT" != "success" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE - 30))
            OVERALL_STATUS="warning"
            echo "âš ï¸ Quality checks issues detected"
          else
            echo "âœ… All quality checks passed"
          fi

          # è¯„ä¼°æµ‹è¯•ç»“æžœ
          TESTING_RESULT="${{ needs.intelligent-testing.result }}"
          if [ "$TESTING_RESULT" != "success" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE - 40))
            OVERALL_STATUS="failed"
            DEPLOYMENT_READY="false"
            echo "âŒ Test failures detected"
          else
            echo "âœ… All tests passed"
          fi

          # è¯„ä¼°æž„å»ºç»“æžœ
          BUILD_RESULT="${{ needs.intelligent-build.result }}"
          if [ "$BUILD_RESULT" != "success" ]; then
            QUALITY_SCORE=$((QUALITY_SCORE - 30))
            OVERALL_STATUS="failed"
            DEPLOYMENT_READY="false"
            echo "âŒ Build failed"
          else
            echo "âœ… Build successful"
          fi

          # æ™ºèƒ½éƒ¨ç½²ç­–ç•¥é€‰æ‹©
          RISK_LEVEL="${{ needs.intelligent-precheck.outputs.deployment-risk }}"
          if [ "$RISK_LEVEL" == "high" ]; then
            DEPLOYMENT_STRATEGY="canary"
            QUALITY_SCORE=$((QUALITY_SCORE - 5))
          elif [ "$RISK_LEVEL" == "medium" ]; then
            DEPLOYMENT_STRATEGY="blue-green"
          else
            DEPLOYMENT_STRATEGY="rolling"
          fi

          # ç¡®ä¿åˆ†æ•°ä¸ä½ŽäºŽ0
          if [ $QUALITY_SCORE -lt 0 ]; then
            QUALITY_SCORE=0
          fi

          # è®¾ç½®è¾“å‡º
          echo "overall-status=$OVERALL_STATUS" >> $GITHUB_OUTPUT
          echo "quality-score=$QUALITY_SCORE" >> $GITHUB_OUTPUT
          echo "deployment-ready=$DEPLOYMENT_READY" >> $GITHUB_OUTPUT
          echo "deployment-strategy=$DEPLOYMENT_STRATEGY" >> $GITHUB_OUTPUT

          echo "ðŸ“Š Quality Score: $QUALITY_SCORE/100"
          echo "ðŸš¦ Overall Status: $OVERALL_STATUS"
          echo "ðŸš€ Deployment Ready: $DEPLOYMENT_READY"
          echo "ðŸŽ¯ Deployment Strategy: $DEPLOYMENT_STRATEGY"
          echo "::endgroup::"

      - name: ðŸ“‹ Generate Comprehensive Quality Report
        if: always()
        run: |
          echo "ðŸ“‹ Generating comprehensive quality report..."

          mkdir -p final-reports

          cat > final-reports/comprehensive-quality-report.md << EOF
          # LLMChat Advanced CI/CD Quality Report

          ## ðŸ“Š Executive Summary
          - **Quality Score**: ${{ steps.gates.outputs.quality-score }}/100
          - **Overall Status**: ${{ steps.gates.outputs.overall-status }}
          - **Deployment Ready**: ${{ steps.gates.outputs.deployment-ready }}
          - **Deployment Strategy**: ${{ steps.gates.outputs.deployment-strategy }}
          - **Build Number**: ${{ github.run_number }}
          - **Commit SHA**: ${{ github.sha }}
          - **Branch**: ${{ github.ref_name }}
          - **Triggered By**: ${{ github.event_name }}

          ## ðŸ§  Intelligent Analysis Results
          - **Build Strategy**: ${{ needs.intelligent-precheck.outputs.build-strategy }}
          - **Test Scope**: ${{ needs.intelligent-precheck.outputs.test-scope }}
          - **Security Level**: ${{ needs.intelligent-precheck.outputs.security-level }}
          - **Deployment Risk**: ${{ needs.intelligent-precheck.outputs.deployment-risk }}
          - **Cache Strategy**: ${{ needs.intelligent-precheck.outputs.cache-strategy }}

          ## ðŸ›¡ï¸ Quality Gates Results

          ### Quality Checks
          - **Status**: ${{ needs.intelligent-quality-checks.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }}
          - **Impact**: Critical for code maintainability

          ### Testing Suite
          - **Status**: ${{ needs.intelligent-testing.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }}
          - **Impact**: Critical for functionality assurance

          ### Build Validation
          - **Status**: ${{ needs.intelligent-build.result == 'success' && 'âœ… Passed' || 'âŒ Failed' }}
          - **Impact**: Critical for deployment readiness

          ## ðŸŽ¯ Intelligent Recommendations

          ${{ steps.gates.outputs.quality-score >= 90 && 'ðŸŒŸ Excellent quality! Ready for immediate deployment.' || '' }}
          ${{ steps.gates.outputs.quality-score >= 80 && steps.gates.outputs.quality-score < 90 && 'âœ… Good quality. Ready for deployment with monitoring.' || '' }}
          ${{ steps.gates.outputs.quality-score >= 70 && steps.gates.outputs.quality-score < 80 && 'âš ï¸ Acceptable quality. Deploy with caution and enhanced monitoring.' || '' }}
          ${{ steps.gates.outputs.quality-score < 70 && 'âŒ Poor quality. Significant improvements required before deployment.' || '' }}

          ## ðŸš€ Deployment Strategy Recommendation

          Based on the analysis, the recommended deployment strategy is: **${{ steps.gates.outputs.deployment-strategy }}**

          ${{ steps.gates.outputs.deployment-strategy == 'canary' && 'ðŸ”¥ Canary deployment recommended due to high risk factors.' || '' }}
          ${{ steps.gates.outputs.deployment-strategy == 'blue-green' && 'ðŸ”„ Blue-green deployment recommended for medium risk changes.' || '' }}
          ${{ steps.gates.outputs.deployment-strategy == 'rolling' && 'âš¡ Rolling deployment recommended for low risk changes.' || '' }}

          ---
          *Report generated on $(date -u)*
          *Powered by LLMChat Advanced CI/CD Pipeline*
          EOF

      - name: ðŸ“¤ Upload Final Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-quality-report
          path: final-reports/
          retention-days: 90

      - name: ðŸš« Quality Gates Enforcement
        if: steps.gates.outputs.overall-status == 'failed'
        run: |
          echo "âŒ Quality gates failed - blocking deployment"
          echo "ðŸ“Š Quality Score: ${{ steps.gates.outputs.quality-score }}/100"
          echo "ðŸš¦ Overall Status: ${{ steps.gates.outputs.overall-status }}"
          exit 1

  # ==========================================
  # é˜¶æ®µ7: æ™ºèƒ½åŒ–éƒ¨ç½²
  # ==========================================
  intelligent-deployment:
    name: ðŸš€ Intelligent Deployment System
    runs-on: ubuntu-latest
    needs: [intelligent-quality-gates, containerization, intelligent-precheck]
    if: needs.intelligent-quality-gates.outputs.deployment-ready == 'true' && github.event_name != 'pull_request'
    environment:
      name: ${{ github.event.inputs.environment || 'development' }}
      url: ${{ steps.deploy.outputs.url }}

    strategy:
      matrix:
        environment: [development, staging, production]
        include:
          - environment: development
            branch: develop
            required_score: 70
            rollout_percent: 100
          - environment: staging
            branch: main
            required_score: 80
            rollout_percent: 100
          - environment: production
            branch: main
            required_score: 90
            rollout_percent: 20
        exclude:
          - environment: production
            branch: develop
          - environment: staging
            branch: develop

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ³ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: ðŸ” Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.DOCKER_REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: ðŸš€ Intelligent Deploy to ${{ matrix.environment }}
        id: deploy
        run: |
          echo "::group::Intelligent Deploy to ${{ matrix.environment }}"

          # éªŒè¯éƒ¨ç½²æ¡ä»¶
          QUALITY_SCORE=${{ needs.intelligent-quality-gates.outputs.quality-score }}
          REQUIRED_SCORE=${{ matrix.required_score }}

          if [ "$QUALITY_SCORE" -lt "$REQUIRED_SCORE" ]; then
            echo "âŒ Quality score $QUALITY_SCORE is below required $REQUIRED_SCORE for ${{ matrix.environment }}"
            exit 1
          fi

          # æ™ºèƒ½éƒ¨ç½²ç­–ç•¥
          DEPLOYMENT_STRATEGY="${{ needs.intelligent-quality-gates.outputs.deployment-strategy }}"
          ROLLOUT_PERCENT="${{ matrix.rollout_percent }}"

          echo "ðŸš€ Deploying to ${{ matrix.environment }} with strategy: $DEPLOYMENT_STRATEGY"
          echo "ðŸ“Š Quality Score: $QUALITY_SCORE/$REQUIRED_SCORE"
          echo "ðŸ“ˆ Rollout Percent: $ROLLOUT_PERCENT%"

          # è®¾ç½®éƒ¨ç½²URL
          if [ "${{ matrix.environment }}" == "development" ]; then
            echo "url=https://dev.llmchat.example.com" >> $GITHUB_OUTPUT
          elif [ "${{ matrix.environment }}" == "staging" ]; then
            echo "url=https://staging.llmchat.example.com" >> $GITHUB_OUTPUT
          elif [ "${{ matrix.environment }}" == "production" ]; then
            echo "url=https://llmchat.example.com" >> $GITHUB_OUTPUT
          fi

          # å®žé™…éƒ¨ç½²é€»è¾‘ï¼ˆç¤ºä¾‹ï¼‰
          echo "âœ… Deployment to ${{ matrix.environment }} completed"
          echo "::endgroup::"

      - name: ðŸ” Intelligent Post-Deployment Health Check
        run: |
          echo "::group::Intelligent Post-Deployment Health Check"

          # ç­‰å¾…éƒ¨ç½²å¯åŠ¨
          sleep 30

          # å¥åº·æ£€æŸ¥
          DEPLOY_URL="${{ steps.deploy.outputs.url }}"
          if [ -n "$DEPLOY_URL" ]; then
            echo "ðŸ” Checking health at $DEPLOY_URL"

            # APIå¥åº·æ£€æŸ¥
            if curl -f "$DEPLOY_URL/api/health" --max-time 30 --retry 3 --retry-delay 10; then
              echo "âœ… API health check passed"
            else
              echo "âŒ API health check failed"
              if [ "${{ github.event.inputs.rollback_enabled }}" == "true" ]; then
                echo "ðŸ”„ Initiating automatic rollback..."
                # è¿™é‡Œæ·»åŠ å›žæ»šé€»è¾‘
              fi
              exit 1
            fi

            # å‰ç«¯å¥åº·æ£€æŸ¥
            if curl -f "$DEPLOY_URL" --max-time 30 --retry 3 --retry-delay 10; then
              echo "âœ… Frontend health check passed"
            else
              echo "âŒ Frontend health check failed"
              exit 1
            fi
          fi

          echo "::endgroup::"

      - name: ðŸ“Š Deployment Metrics & Analytics
        run: |
          echo "::group::Deployment Metrics & Analytics"

          echo "ðŸ“Š Deployment metrics for ${{ matrix.environment }}:"
          echo "- Environment: ${{ matrix.environment }}"
          echo "- Quality Score: ${{ needs.intelligent-quality-gates.outputs.quality-score }}/100"
          echo "- Required Score: ${{ matrix.required_score }}"
          echo "- Deployment Strategy: ${{ needs.intelligent-quality-gates.outputs.deployment-strategy }}"
          echo "- Rollout Percent: ${{ matrix.rollout_percent }}%"
          echo "- Deployment URL: ${{ steps.deploy.outputs.url }}"
          echo "- Deployment Time: $(date -u)"
          echo "- Build Number: ${{ github.run_number }}"
          echo "- Commit SHA: ${{ github.sha }}"

          echo "::endgroup::"

  # ==========================================
  # é˜¶æ®µ8: æ™ºèƒ½åŒ–æ€§èƒ½æµ‹è¯•
  # ==========================================
  intelligent-performance-testing:
    name: ðŸ“Š Intelligent Performance Testing
    runs-on: ubuntu-latest
    needs: [intelligent-deployment, intelligent-precheck]
    if: needs.intelligent-deployment.result == 'success' && (github.event.inputs.performance_test == 'true' || github.ref == 'refs/heads/main')

    steps:
      - name: ðŸ“¥ Checkout Code
        uses: actions/checkout@v4

      - name: ðŸ”§ Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: ðŸ“¦ Install Performance Testing Tools
        run: |
          npm install -g artillery
          npm install -g lighthouse
          npm install -g @lhci/cli

      - name: ðŸš€ Intelligent API Performance Test
        run: |
          echo "::group::Intelligent API Performance Testing"

          # åˆ›å»ºæ™ºèƒ½æ€§èƒ½æµ‹è¯•é…ç½®
          cat > artillery-config.yml << EOF
          config:
            target: 'https://staging.llmchat.example.com/api'
            phases:
              - duration: 60
                arrivalRate: 10
                name: "Warm up"
              - duration: 120
                arrivalRate: 25
                name: "Load test"
              - duration: 60
                arrivalRate: 50
                name: "Stress test"
            processor: "./test-processor.js"

          scenarios:
            - name: "Health Check Load Test"
              weight: 30
              requests:
                - get:
                    url: "/health"
            - name: "API Endpoints Load Test"
              weight: 50
              requests:
                - get:
                    url: "/agents"
                - get:
                    url: "/sessions"
            - name: "Chat API Stress Test"
              weight: 20
              requests:
                - post:
                    url: "/chat/completions"
                    json:
                      model: "test"
                      messages: [{"role": "user", "content": "Hello, performance test!"}]
          EOF

          # è¿è¡ŒAPIæ€§èƒ½æµ‹è¯•
          artillery run artillery-config.yml --output api-performance-results.json

          # åˆ†æžç»“æžœ
          echo "ðŸ“Š API Performance Results:"
          if [ -f "api-performance-results.json" ]; then
            jq '.aggregate | {rps: .http.responses, latency: .latency, errors: .errors}' api-performance-results.json
          fi

          echo "::endgroup::"

      - name: ðŸŒ Intelligent Frontend Performance Test
        run: |
          echo "::group::Intelligent Frontend Performance Testing"

          # åˆ›å»ºLighthouseé…ç½®
          mkdir -p lighthouse-reports

          # è¿è¡ŒLighthouseæµ‹è¯•
          lighthouse "https://staging.llmchat.example.com" \
            --output=json --output=path=./lighthouse-reports/report.json \
            --chrome-flags="--headless --no-sandbox" \
            --quiet

          # åˆ†æžç»“æžœ
          if [ -f "lighthouse-reports/report.json" ]; then
            echo "ðŸŒ Frontend Performance Results:"
            jq '.lhrCategories | {performance: .performance.score, accessibility: .accessibility.score, "best-practices": .["best-practices"].score, seo: .seo.score}' lighthouse-reports/report.json
          fi

          echo "::endgroup::"

      - name: ðŸ“Š Performance Analysis & Recommendations
        run: |
          echo "::group::Performance Analysis & Recommendations"

          # åˆ›å»ºæ€§èƒ½åˆ†æžæŠ¥å‘Š
          mkdir -p performance-analysis

          cat > performance-analysis/performance-report.md << EOF
          # Performance Testing Report

          ## ðŸ“Š Test Summary
          - **Test Date**: $(date -u)
          - **Environment**: staging
          - **Test Type**: Load and Performance Testing

          ## ðŸš€ API Performance Results

          $(if [ -f "api-performance-results.json" ]; then
            echo "- **Requests per Second**: $(jq -r '.aggregate.http.requests' api-performance-results.json 2>/dev/null || echo 'N/A')"
            echo "- **Response Time**: $(jq -r '.aggregate.latency.mean' api-performance-results.json 2>/dev/null || echo 'N/A')ms"
            echo "- **Error Rate**: $(jq -r '.aggregate.errors' api-performance-results.json 2>/dev/null || echo '0')"
          else
            echo "- No API performance results available"
          fi)

          ## ðŸŒ Frontend Performance Results

          $(if [ -f "lighthouse-reports/report.json" ]; then
            echo "- **Performance Score**: $(jq -r '.lhrCategories.performance.score * 100' lighthouse-reports/report.json 2>/dev/null || echo 'N/A')"
            echo "- **Accessibility Score**: $(jq -r '.lhrCategories.accessibility.score * 100' lighthouse-reports/report.json 2>/dev/null || echo 'N/A')"
            echo "- **Best Practices Score**: $(jq -r '.lhrCategories["best-practices"].score * 100' lighthouse-reports/report.json 2>/dev/null || echo 'N/A')"
            echo "- **SEO Score**: $(jq -r '.lhrCategories.seo.score * 100' lighthouse-reports/report.json 2>/dev/null || echo 'N/A')"
          else
            echo "- No frontend performance results available"
          fi)

          ## ðŸ’¡ Performance Recommendations

          - Monitor API response times under load
          - Optimize database queries if needed
          - Implement caching strategies
          - Consider CDN for static assets
          - Optimize images and lazy loading

          EOF

          echo "::endgroup::"

      - name: ðŸ“¤ Upload Performance Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-testing-results
          path: |
            api-performance-results.json
            lighthouse-reports/
            performance-analysis/
          retention-days: 30

  # ==========================================
  # é˜¶æ®µ9: æ™ºèƒ½åŒ–é€šçŸ¥å’ŒæŠ¥å‘Š
  # ==========================================
  intelligent-notification:
    name: ðŸ“¢ Intelligent Notification & Reporting
    runs-on: ubuntu-latest
    needs: [intelligent-quality-gates, intelligent-deployment, intelligent-performance-testing]
    if: always()

    steps:
      - name: ðŸ“Š Download Final Report
        if: always()
        uses: actions/download-artifact@v4
        with:
          name: comprehensive-quality-report
          path: final-report/

      - name: ðŸ“¢ Intelligent Pipeline Summary
        if: always()
        run: |
          echo "# ðŸš€ LLMChat Advanced CI/CD Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ“Š Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Quality Gates**: ${{ needs.intelligent-quality-gates.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Quality Score**: ${{ needs.intelligent-quality-gates.outputs.quality-score }}/100" >> $GITHUB_STEP_SUMMARY
          echo "- **Deployment Strategy**: ${{ needs.intelligent-quality-gates.outputs.deployment-strategy }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Deployment**: ${{ needs.intelligent-deployment.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Performance Tests**: ${{ needs.intelligent-performance-testing.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ needs.intelligent-quality-gates.result }}" == "success" ] && [ "${{ needs.intelligent-deployment.result }}" == "success" ]; then
            echo "## ðŸŽ‰ Overall Status: SUCCESS" >> $GITHUB_STEP_SUMMARY
            echo "âœ… Pipeline completed successfully!" >> $GITHUB_STEP_SUMMARY
          else
            echo "## âŒ Overall Status: FAILED" >> $GITHUB_STEP_SUMMARY
            echo "âŒ Pipeline failed, please review the logs." >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ðŸ§  Intelligent Analysis" >> $GITHUB_STEP_SUMMARY
          echo "- **Build Strategy**: ${{ needs.intelligent-precheck.outputs.build-strategy }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Scope**: ${{ needs.intelligent-precheck.outputs.test-scope }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Security Level**: ${{ needs.intelligent-precheck.outputs.security-level }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Deployment Risk**: ${{ needs.intelligent-precheck.outputs.deployment-risk }}" >> $GITHUB_STEP_SUMMARY

      - name: ðŸ’¬ Intelligent PR Comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            try {
              const reportPath = 'final-report/comprehensive-quality-report.md';
              if (fs.existsSync(reportPath)) {
                const report = fs.readFileSync(reportPath, 'utf8');

                await github.rest.issues.createComment({
                  issue_number: context.issue.number,
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  body: `## ðŸ›¡ï¸ Advanced CI/CD Quality Report\n\n${report}`
                });

                console.log('âœ… Quality report commented to PR');
              }
            } catch (error) {
              console.log('âŒ Error commenting PR:', error.message);
            }

      - name: ðŸ“§ Intelligent Notification System
        if: always()
        run: |
          echo "::group::Intelligent Notification System"

          # æ ¹æ®ç»“æžœæ™ºèƒ½é€šçŸ¥
          if [ "${{ needs.intelligent-quality-gates.result }}" == "success" ] && [ "${{ needs.intelligent-deployment.result }}" == "success" ]; then
            echo "âœ… Pipeline completed successfully!"
            echo "ðŸŽ‰ Deployment completed to ${{ github.event.inputs.environment || 'development' }}"
            # è¿™é‡Œå¯ä»¥æ·»åŠ Slackã€Teamsã€é‚®ä»¶ç­‰æˆåŠŸé€šçŸ¥
          else
            echo "âŒ Pipeline failed - sending failure notification"
            # è¿™é‡Œå¯ä»¥æ·»åŠ å¤±è´¥é€šçŸ¥é€»è¾‘
          fi

          echo "::endgroup::"

      - name: ðŸ“ˆ Metrics Collection & Analytics
        if: always()
        run: |
          echo "::group::Metrics Collection & Analytics"

          # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
          METRICS_FILE="pipeline-metrics.json"

          cat > $METRICS_FILE << EOF
          {
            "pipeline": {
              "run_id": "${{ github.run_id }}",
              "run_number": ${{ github.run_number }},
              "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
              "branch": "${{ github.ref_name }}",
              "commit": "${{ github.sha }}",
              "event": "${{ github.event_name }}"
            },
            "quality": {
              "score": ${{ needs.intelligent-quality-gates.outputs.quality-score }},
              "status": "${{ needs.intelligent-quality-gates.result }}",
              "deployment_ready": "${{ needs.intelligent-quality-gates.outputs.deployment-ready }}"
            },
            "deployment": {
              "status": "${{ needs.intelligent-deployment.result }}",
              "strategy": "${{ needs.intelligent-quality-gates.outputs.deployment-strategy }}"
            },
            "performance": {
              "status": "${{ needs.intelligent-performance-testing.result }}"
            },
            "analysis": {
              "build_strategy": "${{ needs.intelligent-precheck.outputs.build-strategy }}",
              "test_scope": "${{ needs.intelligent-precheck.outputs.test-scope }}",
              "security_level": "${{ needs.intelligent-precheck.outputs.security-level }}",
              "deployment_risk": "${{ needs.intelligent-precheck.outputs.deployment-risk }}"
            }
          }
          EOF

          echo "ðŸ“Š Metrics collected and saved to $METRICS_FILE"

          echo "::endgroup::"

      - name: ðŸ“¤ Upload Pipeline Metrics
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-metrics
          path: pipeline-metrics.json
          retention-days: 90